<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Liveness Detection</title>
    <style>
        :root {
            --primary-color: #4a90d9;
            --success-color: #4caf50;
            --error-color: #f44336;
            --warning-color: #ff9800;
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #ffffff;
            --text-muted: #a0a0a0;
            --border-radius: 12px;
            --transition-speed: 0.3s;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            width: 100%;
            max-width: 600px;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }

        /* Header Section */
        .header {
            text-align: center;
            width: 100%;
        }

        .header h1 {
            font-size: 1.8rem;
            font-weight: 600;
            margin-bottom: 8px;
        }

        .header p {
            color: var(--text-muted);
            font-size: 0.95rem;
        }

        /* Video Container */
        .video-container {
            position: relative;
            width: 100%;
            max-width: 480px;
            aspect-ratio: 4/3;
            background: var(--card-bg);
            border-radius: var(--border-radius);
            overflow: hidden;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }

        #video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1); /* Mirror the video */
        }

        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }

        /* Face Guide Overlay */
        .face-guide {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 55%;
            height: 70%;
            border: 3px dashed var(--primary-color);
            border-radius: 50%;
            opacity: 0.7;
            transition: border-color var(--transition-speed), opacity var(--transition-speed);
        }

        .face-guide.detected {
            border-color: var(--success-color);
            border-style: solid;
            opacity: 1;
        }

        .face-guide.warning {
            border-color: var(--warning-color);
        }

        /* Status Overlay */
        .status-overlay {
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            background: linear-gradient(transparent, rgba(0, 0, 0, 0.8));
            padding: 40px 20px 20px;
            text-align: center;
        }

        .status-text {
            font-size: 1.1rem;
            font-weight: 500;
        }

        /* Challenge Panel */
        .challenge-panel {
            width: 100%;
            max-width: 480px;
            background: var(--card-bg);
            border-radius: var(--border-radius);
            padding: 24px;
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.2);
        }

        .challenge-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 16px;
        }

        .challenge-title {
            font-size: 1.1rem;
            font-weight: 600;
        }

        .challenge-timer {
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        .challenge-instruction {
            display: flex;
            align-items: center;
            gap: 16px;
            padding: 16px;
            background: rgba(74, 144, 217, 0.1);
            border-radius: 8px;
            margin-bottom: 16px;
        }

        .challenge-icon {
            font-size: 2.5rem;
            flex-shrink: 0;
        }

        .challenge-text {
            flex: 1;
        }

        .challenge-text h3 {
            font-size: 1.2rem;
            margin-bottom: 4px;
        }

        .challenge-text p {
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        /* Progress Bar */
        .progress-container {
            width: 100%;
        }

        .progress-label {
            display: flex;
            justify-content: space-between;
            margin-bottom: 8px;
            font-size: 0.85rem;
            color: var(--text-muted);
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 4px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: var(--primary-color);
            border-radius: 4px;
            width: 0%;
            transition: width var(--transition-speed);
        }

        .progress-fill.success {
            background: var(--success-color);
        }

        /* Progress Indicators */
        .progress-indicators {
            display: flex;
            justify-content: center;
            gap: 12px;
            margin-top: 16px;
        }

        .indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: rgba(255, 255, 255, 0.2);
            transition: background var(--transition-speed), transform var(--transition-speed);
        }

        .indicator.active {
            background: var(--primary-color);
            transform: scale(1.2);
        }

        .indicator.completed {
            background: var(--success-color);
        }

        .indicator.failed {
            background: var(--error-color);
        }

        /* Control Button */
        .control-btn {
            width: 100%;
            max-width: 480px;
            padding: 16px 32px;
            font-size: 1.1rem;
            font-weight: 600;
            color: white;
            background: var(--primary-color);
            border: none;
            border-radius: var(--border-radius);
            cursor: pointer;
            transition: background var(--transition-speed), transform 0.1s;
        }

        .control-btn:hover {
            background: #3a7bc8;
        }

        .control-btn:active {
            transform: scale(0.98);
        }

        .control-btn:disabled {
            background: var(--text-muted);
            cursor: not-allowed;
        }

        /* Result Screen */
        .result-screen {
            display: none;
            text-align: center;
            padding: 40px 20px;
        }

        .result-screen.visible {
            display: block;
        }

        .result-icon {
            font-size: 4rem;
            margin-bottom: 16px;
        }

        .result-title {
            font-size: 1.5rem;
            font-weight: 600;
            margin-bottom: 8px;
        }

        .result-message {
            color: var(--text-muted);
            margin-bottom: 24px;
        }

        /* Error Message */
        .error-message {
            display: none;
            background: rgba(244, 67, 54, 0.1);
            border: 1px solid var(--error-color);
            border-radius: 8px;
            padding: 16px;
            text-align: center;
            color: var(--error-color);
        }

        .error-message.visible {
            display: block;
        }

        /* Responsive Adjustments */
        @media (max-width: 480px) {
            .header h1 {
                font-size: 1.5rem;
            }

            .challenge-panel {
                padding: 16px;
            }

            .challenge-instruction {
                flex-direction: column;
                text-align: center;
            }

            .challenge-icon {
                font-size: 2rem;
            }
        }

        /* Loading State */
        .loading {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            gap: 16px;
            padding: 40px;
        }

        .spinner {
            width: 48px;
            height: 48px;
            border: 4px solid rgba(255, 255, 255, 0.1);
            border-top-color: var(--primary-color);
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            to {
                transform: rotate(360deg);
            }
        }

        /* Hidden utility class */
        .hidden {
            display: none !important;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Header -->
        <div class="header">
            <h1>Liveness Verification</h1>
            <p>Complete the challenges to verify you're a real person</p>
        </div>

        <!-- Video Container -->
        <div class="video-container">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas"></canvas>
            <div class="face-guide" id="faceGuide"></div>
            <div class="status-overlay">
                <p class="status-text" id="statusText">Initializing camera...</p>
            </div>
        </div>

        <!-- Error Message -->
        <div class="error-message" id="errorMessage">
            <p id="errorText">Camera access denied. Please allow camera access and refresh the page.</p>
        </div>

        <!-- Challenge Panel -->
        <div class="challenge-panel" id="challengePanel">
            <div class="challenge-header">
                <span class="challenge-title">Challenge <span id="challengeNumber">1</span> of 4</span>
                <span class="challenge-timer" id="challengeTimer">5s remaining</span>
            </div>
            <div class="challenge-instruction">
                <span class="challenge-icon" id="challengeIcon">üëÅ</span>
                <div class="challenge-text">
                    <h3 id="challengeName">Blink Your Eyes</h3>
                    <p id="challengeHint">Blink naturally 2-3 times</p>
                </div>
            </div>
            <div class="progress-container">
                <div class="progress-label">
                    <span>Hold progress</span>
                    <span id="holdPercent">0%</span>
                </div>
                <div class="progress-bar">
                    <div class="progress-fill" id="progressFill"></div>
                </div>
            </div>
            <div class="progress-indicators">
                <div class="indicator active" id="indicator1"></div>
                <div class="indicator" id="indicator2"></div>
                <div class="indicator" id="indicator3"></div>
                <div class="indicator" id="indicator4"></div>
            </div>
        </div>

        <!-- Control Button -->
        <button class="control-btn" id="controlBtn">Start Verification</button>

        <!-- Result Screen -->
        <div class="result-screen" id="resultScreen">
            <div class="result-icon" id="resultIcon">‚úì</div>
            <h2 class="result-title" id="resultTitle">Verification Complete</h2>
            <p class="result-message" id="resultMessage">You have been verified as a real person.</p>
            <button class="control-btn" id="retryBtn">Try Again</button>
        </div>
    </div>

    <!-- MediaPipe Tasks Vision CDN -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.js" crossorigin="anonymous"></script>

    <script>
        // DOM Elements references
        const elements = {
            video: document.getElementById('video'),
            canvas: document.getElementById('canvas'),
            faceGuide: document.getElementById('faceGuide'),
            statusText: document.getElementById('statusText'),
            errorMessage: document.getElementById('errorMessage'),
            errorText: document.getElementById('errorText'),
            challengePanel: document.getElementById('challengePanel'),
            challengeNumber: document.getElementById('challengeNumber'),
            challengeTimer: document.getElementById('challengeTimer'),
            challengeIcon: document.getElementById('challengeIcon'),
            challengeName: document.getElementById('challengeName'),
            challengeHint: document.getElementById('challengeHint'),
            holdPercent: document.getElementById('holdPercent'),
            progressFill: document.getElementById('progressFill'),
            indicators: [
                document.getElementById('indicator1'),
                document.getElementById('indicator2'),
                document.getElementById('indicator3'),
                document.getElementById('indicator4')
            ],
            controlBtn: document.getElementById('controlBtn'),
            resultScreen: document.getElementById('resultScreen'),
            resultIcon: document.getElementById('resultIcon'),
            resultTitle: document.getElementById('resultTitle'),
            resultMessage: document.getElementById('resultMessage'),
            retryBtn: document.getElementById('retryBtn')
        };

        // FaceLandmarker configuration
        const FACE_LANDMARKER_MODEL_URL = 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task';

        // Global state
        let faceLandmarker = null;
        let isModelLoading = false;
        let isModelReady = false;
        let videoStream = null;
        let isCameraReady = false;

        // Detection loop state
        let isDetectionRunning = false;
        let detectionAnimationId = null;
        let lastDetectionTime = 0;
        let currentFaceResults = null;

        /**
         * Initialize FaceLandmarker with GPU delegate
         * Loads the model from CDN and configures it for face detection with blendshapes
         */
        async function initializeFaceLandmarker() {
            if (isModelLoading || isModelReady) return;

            isModelLoading = true;
            updateStatus('Loading face detection model...');

            try {
                const { FaceLandmarker, FilesetResolver } = vision;

                // Load the WASM files from CDN
                const filesetResolver = await FilesetResolver.forVisionTasks(
                    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm'
                );

                // Create FaceLandmarker with GPU delegate and blendshapes enabled
                faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: FACE_LANDMARKER_MODEL_URL,
                        delegate: 'GPU' // Use GPU for better performance
                    },
                    runningMode: 'VIDEO',
                    numFaces: 1,
                    outputFaceBlendshapes: true, // Enable blendshapes for expression detection
                    outputFacialTransformationMatrixes: true // Enable for head pose estimation
                });

                isModelReady = true;
                isModelLoading = false;
                console.log('FaceLandmarker initialized successfully with GPU delegate');

                return true;
            } catch (error) {
                isModelLoading = false;
                console.error('Failed to initialize FaceLandmarker:', error);

                // Try fallback to CPU if GPU fails
                if (error.message && error.message.includes('GPU')) {
                    console.log('GPU delegate failed, attempting CPU fallback...');
                    return await initializeFaceLandmarkerCPU();
                }

                showError('Failed to load face detection model. Please refresh the page.');
                return false;
            }
        }

        /**
         * Fallback initialization with CPU delegate
         */
        async function initializeFaceLandmarkerCPU() {
            try {
                const { FaceLandmarker, FilesetResolver } = vision;

                const filesetResolver = await FilesetResolver.forVisionTasks(
                    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm'
                );

                faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: FACE_LANDMARKER_MODEL_URL,
                        delegate: 'CPU'
                    },
                    runningMode: 'VIDEO',
                    numFaces: 1,
                    outputFaceBlendshapes: true,
                    outputFacialTransformationMatrixes: true
                });

                isModelReady = true;
                isModelLoading = false;
                console.log('FaceLandmarker initialized with CPU delegate (fallback)');

                return true;
            } catch (error) {
                console.error('CPU fallback also failed:', error);
                showError('Failed to load face detection model. Please try a different browser.');
                return false;
            }
        }

        /**
         * Update status text displayed to user
         */
        function updateStatus(message) {
            elements.statusText.textContent = message;
        }

        /**
         * Show error message to user
         */
        function showError(message) {
            elements.errorText.textContent = message;
            elements.errorMessage.classList.add('visible');
            elements.controlBtn.disabled = true;
        }

        /**
         * Hide error message
         */
        function hideError() {
            elements.errorMessage.classList.remove('visible');
        }

        /**
         * Check if FaceLandmarker is ready for detection
         */
        function isFaceLandmarkerReady() {
            return isModelReady && faceLandmarker !== null;
        }

        /**
         * Initialize WebRTC camera with getUserMedia
         * Requests camera access and sets up the video stream with mirrored view
         */
        async function initializeCamera() {
            updateStatus('Requesting camera access...');

            // Define video constraints for optimal face detection
            const constraints = {
                video: {
                    width: { ideal: 640, max: 1280 },
                    height: { ideal: 480, max: 720 },
                    facingMode: 'user', // Front-facing camera
                    frameRate: { ideal: 30, max: 60 }
                },
                audio: false
            };

            try {
                // Request camera access
                videoStream = await navigator.mediaDevices.getUserMedia(constraints);

                // Attach stream to video element
                elements.video.srcObject = videoStream;

                // Wait for video to be ready
                await new Promise((resolve, reject) => {
                    elements.video.onloadedmetadata = () => {
                        // Set canvas dimensions to match video
                        elements.canvas.width = elements.video.videoWidth;
                        elements.canvas.height = elements.video.videoHeight;
                        resolve();
                    };
                    elements.video.onerror = () => {
                        reject(new Error('Video failed to load'));
                    };
                });

                // Play the video
                await elements.video.play();

                isCameraReady = true;
                updateStatus('Camera ready');
                console.log(`Camera initialized: ${elements.video.videoWidth}x${elements.video.videoHeight}`);

                return true;
            } catch (error) {
                console.error('Camera initialization failed:', error);
                isCameraReady = false;

                // Handle specific error types
                if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                    showError('Camera access denied. Please allow camera access and refresh the page.');
                } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
                    showError('No camera found. Please connect a camera and refresh the page.');
                } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
                    showError('Camera is in use by another application. Please close other apps using the camera.');
                } else if (error.name === 'OverconstrainedError') {
                    // Try again with less strict constraints
                    console.log('Constraints too strict, retrying with basic constraints...');
                    return await initializeCameraBasic();
                } else {
                    showError(`Camera error: ${error.message || 'Unknown error occurred'}`);
                }

                return false;
            }
        }

        /**
         * Fallback camera initialization with basic constraints
         * Used when ideal constraints cannot be satisfied
         */
        async function initializeCameraBasic() {
            const basicConstraints = {
                video: { facingMode: 'user' },
                audio: false
            };

            try {
                videoStream = await navigator.mediaDevices.getUserMedia(basicConstraints);
                elements.video.srcObject = videoStream;

                await new Promise((resolve, reject) => {
                    elements.video.onloadedmetadata = () => {
                        elements.canvas.width = elements.video.videoWidth;
                        elements.canvas.height = elements.video.videoHeight;
                        resolve();
                    };
                    elements.video.onerror = () => reject(new Error('Video failed to load'));
                });

                await elements.video.play();

                isCameraReady = true;
                updateStatus('Camera ready (basic mode)');
                console.log(`Camera initialized (basic): ${elements.video.videoWidth}x${elements.video.videoHeight}`);

                return true;
            } catch (error) {
                console.error('Basic camera initialization also failed:', error);
                showError('Unable to access camera. Please check your browser settings.');
                return false;
            }
        }

        /**
         * Stop the camera stream and release resources
         */
        function stopCamera() {
            if (videoStream) {
                videoStream.getTracks().forEach(track => {
                    track.stop();
                    console.log(`Stopped track: ${track.kind}`);
                });
                videoStream = null;
            }
            elements.video.srcObject = null;
            isCameraReady = false;
        }

        /**
         * Check if camera is ready for use
         */
        function isCameraInitialized() {
            return isCameraReady && videoStream !== null && elements.video.readyState >= 2;
        }

        /**
         * Check if both camera and model are ready
         */
        function isAppReady() {
            return isCameraInitialized() && isFaceLandmarkerReady();
        }

        /**
         * Enable the start button when both camera and model are ready
         */
        function checkAndEnableStartButton() {
            if (isAppReady()) {
                elements.controlBtn.disabled = false;
                updateStatus('Position your face in the oval and click Start');
            }
        }

        /**
         * Main detection loop using requestAnimationFrame
         * Continuously processes video frames for face detection
         */
        function detectionLoop(timestamp) {
            if (!isDetectionRunning) {
                return;
            }

            // Check if video is ready and playing
            if (!isCameraInitialized() || elements.video.paused || elements.video.ended) {
                detectionAnimationId = requestAnimationFrame(detectionLoop);
                return;
            }

            // Run face detection
            if (isFaceLandmarkerReady()) {
                try {
                    // Detect faces in the current video frame
                    // Use performance.now() for VIDEO running mode
                    const startTime = performance.now();
                    currentFaceResults = faceLandmarker.detectForVideo(elements.video, startTime);
                    lastDetectionTime = startTime;

                    // Process detection results
                    processDetectionResults(currentFaceResults);
                } catch (error) {
                    console.error('Detection error:', error);
                }
            }

            // Schedule next frame
            detectionAnimationId = requestAnimationFrame(detectionLoop);
        }

        /**
         * Process face detection results
         * Updates UI based on whether a face is detected and its position
         */
        function processDetectionResults(results) {
            const ctx = elements.canvas.getContext('2d');

            // Clear previous drawings
            ctx.clearRect(0, 0, elements.canvas.width, elements.canvas.height);

            // Check if a face was detected
            if (results && results.faceLandmarks && results.faceLandmarks.length > 0) {
                const landmarks = results.faceLandmarks[0];
                const blendshapes = results.faceBlendshapes && results.faceBlendshapes.length > 0
                    ? results.faceBlendshapes[0].categories
                    : null;
                const transformMatrix = results.facialTransformationMatrixes && results.facialTransformationMatrixes.length > 0
                    ? results.facialTransformationMatrixes[0]
                    : null;

                // Update face guide to show detected state
                elements.faceGuide.classList.add('detected');
                elements.faceGuide.classList.remove('warning');

                // Check if face is well-positioned
                const facePosition = checkFacePosition(landmarks);
                if (!facePosition.isWellPositioned) {
                    elements.faceGuide.classList.add('warning');
                    elements.faceGuide.classList.remove('detected');
                    updateStatus(facePosition.message);
                } else {
                    updateStatus('Face detected - Ready');
                }

                // Draw face landmarks on canvas (mirrored to match video)
                drawFaceLandmarks(ctx, landmarks);
            } else {
                // No face detected
                elements.faceGuide.classList.remove('detected');
                elements.faceGuide.classList.remove('warning');
                updateStatus('No face detected - Position your face in the oval');
                currentFaceResults = null;
            }
        }

        /**
         * Check if the face is well-positioned within the guide oval
         * Returns position status and guidance message
         */
        function checkFacePosition(landmarks) {
            // Get face bounding box from landmarks
            // Nose tip (landmark 1) as center reference
            const noseTip = landmarks[1];

            // Calculate face bounds
            let minX = 1, maxX = 0, minY = 1, maxY = 0;
            landmarks.forEach(point => {
                minX = Math.min(minX, point.x);
                maxX = Math.max(maxX, point.x);
                minY = Math.min(minY, point.y);
                maxY = Math.max(maxY, point.y);
            });

            const faceWidth = maxX - minX;
            const faceHeight = maxY - minY;
            const faceCenterX = (minX + maxX) / 2;
            const faceCenterY = (minY + maxY) / 2;

            // Define acceptable ranges (normalized 0-1)
            const centerTolerance = 0.15;
            const minFaceSize = 0.25;
            const maxFaceSize = 0.75;

            // Check horizontal centering (note: x is mirrored)
            if (Math.abs(faceCenterX - 0.5) > centerTolerance) {
                const direction = faceCenterX < 0.5 ? 'right' : 'left';
                return { isWellPositioned: false, message: `Move your face ${direction}` };
            }

            // Check vertical centering
            if (Math.abs(faceCenterY - 0.5) > centerTolerance) {
                const direction = faceCenterY < 0.5 ? 'down' : 'up';
                return { isWellPositioned: false, message: `Move your face ${direction}` };
            }

            // Check face size (too far or too close)
            if (faceWidth < minFaceSize || faceHeight < minFaceSize) {
                return { isWellPositioned: false, message: 'Move closer to the camera' };
            }

            if (faceWidth > maxFaceSize || faceHeight > maxFaceSize) {
                return { isWellPositioned: false, message: 'Move further from the camera' };
            }

            return { isWellPositioned: true, message: 'Face detected - Ready' };
        }

        /**
         * Draw face landmarks on the canvas
         * Draws contours for face mesh visualization
         */
        function drawFaceLandmarks(ctx, landmarks) {
            const width = elements.canvas.width;
            const height = elements.canvas.height;

            // Save context state
            ctx.save();

            // Mirror the canvas to match the mirrored video
            ctx.translate(width, 0);
            ctx.scale(-1, 1);

            // Set drawing style
            ctx.fillStyle = 'rgba(74, 144, 217, 0.6)';
            ctx.strokeStyle = 'rgba(74, 144, 217, 0.8)';
            ctx.lineWidth = 1;

            // Draw key facial contours
            const contours = {
                // Face oval
                faceOval: [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109, 10],
                // Left eye
                leftEye: [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246, 33],
                // Right eye
                rightEye: [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398, 362],
                // Lips outer
                lipsOuter: [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 409, 270, 269, 267, 0, 37, 39, 40, 185, 61]
            };

            // Draw each contour
            Object.values(contours).forEach(indices => {
                ctx.beginPath();
                indices.forEach((index, i) => {
                    const point = landmarks[index];
                    const x = point.x * width;
                    const y = point.y * height;
                    if (i === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }
                });
                ctx.stroke();
            });

            // Draw landmark points for key features
            const keyPoints = [1, 33, 133, 362, 263, 61, 291]; // Nose, eyes, mouth corners
            keyPoints.forEach(index => {
                const point = landmarks[index];
                const x = point.x * width;
                const y = point.y * height;
                ctx.beginPath();
                ctx.arc(x, y, 3, 0, Math.PI * 2);
                ctx.fill();
            });

            // Restore context state
            ctx.restore();
        }

        /**
         * Start the detection loop
         */
        function startDetectionLoop() {
            if (isDetectionRunning) {
                console.log('Detection loop already running');
                return;
            }

            if (!isAppReady()) {
                console.error('Cannot start detection: app not ready');
                return;
            }

            isDetectionRunning = true;
            console.log('Starting detection loop');
            detectionAnimationId = requestAnimationFrame(detectionLoop);
        }

        /**
         * Stop the detection loop
         */
        function stopDetectionLoop() {
            isDetectionRunning = false;

            if (detectionAnimationId) {
                cancelAnimationFrame(detectionAnimationId);
                detectionAnimationId = null;
            }

            // Clear canvas
            const ctx = elements.canvas.getContext('2d');
            ctx.clearRect(0, 0, elements.canvas.width, elements.canvas.height);

            console.log('Detection loop stopped');
        }

        /**
         * Get the current face detection results
         * Used by other modules (BlinkDetector, HeadMovementDetector, etc.)
         */
        function getCurrentFaceResults() {
            return currentFaceResults;
        }

        /**
         * Check if detection is currently running
         */
        function isDetectionActive() {
            return isDetectionRunning;
        }

        // Initialize the app on page load
        document.addEventListener('DOMContentLoaded', async () => {
            console.log('Liveness Detection App - Initializing...');

            // Disable button until both camera and model are ready
            elements.controlBtn.disabled = true;

            // Initialize camera and model in parallel for faster startup
            const [cameraResult, modelResult] = await Promise.all([
                initializeCamera(),
                initializeFaceLandmarker()
            ]);

            // Check if both initialized successfully
            if (cameraResult && modelResult) {
                checkAndEnableStartButton();
                // Start detection loop immediately for face positioning feedback
                startDetectionLoop();
            } else {
                if (!cameraResult) {
                    console.error('Camera initialization failed');
                }
                if (!modelResult) {
                    console.error('Model initialization failed');
                }
            }

            // Control button click handler
            elements.controlBtn.addEventListener('click', () => {
                if (!isAppReady()) {
                    console.error('App not ready');
                    return;
                }

                // Start detection if not running
                if (!isDetectionRunning) {
                    startDetectionLoop();
                }

                // Button will be used to start verification challenges
                // (Challenge state machine will be implemented in Task 10)
                console.log('Verification started');
                updateStatus('Verification in progress...');
            });

            // Retry button click handler
            elements.retryBtn.addEventListener('click', () => {
                // Reset and restart (full implementation in later tasks)
                elements.resultScreen.classList.remove('visible');
                elements.challengePanel.classList.remove('hidden');
                elements.controlBtn.classList.remove('hidden');
                startDetectionLoop();
            });
        });
    </script>
</body>
</html>

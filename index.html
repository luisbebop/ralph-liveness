<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Liveness Detection</title>
    <style>
        :root {
            --primary-color: #4a90d9;
            --success-color: #4caf50;
            --error-color: #f44336;
            --warning-color: #ff9800;
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #ffffff;
            --text-muted: #a0a0a0;
            --border-radius: 12px;
            --transition-speed: 0.3s;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            width: 100%;
            max-width: 600px;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }

        /* Header Section */
        .header {
            text-align: center;
            width: 100%;
        }

        .header h1 {
            font-size: 1.8rem;
            font-weight: 600;
            margin-bottom: 8px;
        }

        .header p {
            color: var(--text-muted);
            font-size: 0.95rem;
        }

        /* Video Container */
        .video-container {
            position: relative;
            width: 100%;
            max-width: 480px;
            aspect-ratio: 4/3;
            background: var(--card-bg);
            border-radius: var(--border-radius);
            overflow: hidden;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }

        #video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1); /* Mirror the video */
        }

        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }

        /* Face Guide Overlay */
        .face-guide {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 55%;
            height: 70%;
            border: 3px dashed var(--primary-color);
            border-radius: 50%;
            opacity: 0.7;
            transition: border-color var(--transition-speed), opacity var(--transition-speed);
        }

        .face-guide.detected {
            border-color: var(--success-color);
            border-style: solid;
            opacity: 1;
        }

        .face-guide.warning {
            border-color: var(--warning-color);
        }

        /* Status Overlay */
        .status-overlay {
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            background: linear-gradient(transparent, rgba(0, 0, 0, 0.8));
            padding: 40px 20px 20px;
            text-align: center;
        }

        .status-text {
            font-size: 1.1rem;
            font-weight: 500;
        }

        /* Challenge Panel */
        .challenge-panel {
            width: 100%;
            max-width: 480px;
            background: var(--card-bg);
            border-radius: var(--border-radius);
            padding: 24px;
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.2);
        }

        .challenge-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 16px;
        }

        .challenge-title {
            font-size: 1.1rem;
            font-weight: 600;
        }

        .challenge-timer {
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        .challenge-instruction {
            display: flex;
            align-items: center;
            gap: 16px;
            padding: 16px;
            background: rgba(74, 144, 217, 0.1);
            border-radius: 8px;
            margin-bottom: 16px;
        }

        .challenge-icon {
            font-size: 2.5rem;
            flex-shrink: 0;
        }

        .challenge-text {
            flex: 1;
        }

        .challenge-text h3 {
            font-size: 1.2rem;
            margin-bottom: 4px;
        }

        .challenge-text p {
            font-size: 0.9rem;
            color: var(--text-muted);
        }

        /* Progress Bar */
        .progress-container {
            width: 100%;
        }

        .progress-label {
            display: flex;
            justify-content: space-between;
            margin-bottom: 8px;
            font-size: 0.85rem;
            color: var(--text-muted);
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 4px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: var(--primary-color);
            border-radius: 4px;
            width: 0%;
            transition: width var(--transition-speed);
        }

        .progress-fill.success {
            background: var(--success-color);
        }

        /* Progress Indicators */
        .progress-indicators {
            display: flex;
            justify-content: center;
            gap: 12px;
            margin-top: 16px;
        }

        .indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: rgba(255, 255, 255, 0.2);
            transition: background var(--transition-speed), transform var(--transition-speed);
        }

        .indicator.active {
            background: var(--primary-color);
            transform: scale(1.2);
        }

        .indicator.completed {
            background: var(--success-color);
        }

        .indicator.failed {
            background: var(--error-color);
        }

        /* Control Button */
        .control-btn {
            width: 100%;
            max-width: 480px;
            padding: 16px 32px;
            font-size: 1.1rem;
            font-weight: 600;
            color: white;
            background: var(--primary-color);
            border: none;
            border-radius: var(--border-radius);
            cursor: pointer;
            transition: background var(--transition-speed), transform 0.1s;
        }

        .control-btn:hover {
            background: #3a7bc8;
        }

        .control-btn:active {
            transform: scale(0.98);
        }

        .control-btn:disabled {
            background: var(--text-muted);
            cursor: not-allowed;
        }

        /* Result Screen */
        .result-screen {
            display: none;
            text-align: center;
            padding: 40px 20px;
        }

        .result-screen.visible {
            display: block;
        }

        .result-screen.failure .result-icon {
            color: var(--error-color);
        }

        .result-screen.failure .result-title {
            color: var(--error-color);
        }

        .result-icon {
            font-size: 4rem;
            margin-bottom: 16px;
            color: var(--success-color);
        }

        .result-title {
            font-size: 1.5rem;
            font-weight: 600;
            margin-bottom: 8px;
        }

        .result-message {
            color: var(--text-muted);
            margin-bottom: 24px;
        }

        /* Error Message */
        .error-message {
            display: none;
            width: 100%;
            max-width: 480px;
            background: rgba(244, 67, 54, 0.1);
            border: 1px solid var(--error-color);
            border-radius: var(--border-radius);
            padding: 24px;
            text-align: center;
        }

        .error-message.visible {
            display: block;
            animation: fadeInUp 0.3s ease-out;
        }

        .error-icon {
            font-size: 3rem;
            margin-bottom: 12px;
        }

        .error-title {
            font-size: 1.2rem;
            font-weight: 600;
            color: var(--error-color);
            margin-bottom: 8px;
        }

        .error-text {
            color: var(--text-muted);
            margin-bottom: 16px;
            font-size: 0.95rem;
            line-height: 1.5;
        }

        .error-actions {
            display: flex;
            gap: 12px;
            justify-content: center;
            flex-wrap: wrap;
        }

        .error-btn {
            padding: 10px 20px;
            font-size: 0.95rem;
            font-weight: 500;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: background var(--transition-speed), transform 0.1s;
        }

        .error-btn:active {
            transform: scale(0.98);
        }

        .error-btn-primary {
            background: var(--primary-color);
            color: white;
        }

        .error-btn-primary:hover {
            background: #3a7bc8;
        }

        .error-btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-color);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .error-btn-secondary:hover {
            background: rgba(255, 255, 255, 0.15);
        }

        /* Warning toast for transient messages */
        .warning-toast {
            position: fixed;
            top: 20px;
            left: 50%;
            transform: translateX(-50%) translateY(-100px);
            background: var(--warning-color);
            color: #1a1a2e;
            padding: 12px 24px;
            border-radius: 8px;
            font-weight: 500;
            z-index: 1000;
            opacity: 0;
            transition: transform 0.3s ease-out, opacity 0.3s ease-out;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        }

        .warning-toast.visible {
            transform: translateX(-50%) translateY(0);
            opacity: 1;
        }

        /* Face detection warning overlay */
        .face-warning-overlay {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(0, 0, 0, 0.8);
            color: var(--warning-color);
            padding: 16px 24px;
            border-radius: 8px;
            text-align: center;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.3s ease-out;
        }

        .face-warning-overlay.visible {
            opacity: 1;
        }

        .face-warning-overlay .warning-icon {
            font-size: 2rem;
            margin-bottom: 8px;
        }

        .face-warning-overlay .warning-text {
            font-size: 1rem;
            font-weight: 500;
        }

        /* Responsive Adjustments */
        @media (max-width: 480px) {
            .header h1 {
                font-size: 1.5rem;
            }

            .challenge-panel {
                padding: 16px;
            }

            .challenge-instruction {
                flex-direction: column;
                text-align: center;
            }

            .challenge-icon {
                font-size: 2rem;
            }
        }

        /* Loading State */
        .loading {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            gap: 16px;
            padding: 40px;
        }

        .spinner {
            width: 48px;
            height: 48px;
            border: 4px solid rgba(255, 255, 255, 0.1);
            border-top-color: var(--primary-color);
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            to {
                transform: rotate(360deg);
            }
        }

        /* Success/Failure Animations */
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes successPulse {
            0% {
                transform: scale(0);
                opacity: 0;
            }
            50% {
                transform: scale(1.2);
            }
            100% {
                transform: scale(1);
                opacity: 1;
            }
        }

        @keyframes failureShake {
            0%, 100% {
                transform: translateX(0);
            }
            10%, 30%, 50%, 70%, 90% {
                transform: translateX(-8px);
            }
            20%, 40%, 60%, 80% {
                transform: translateX(8px);
            }
        }

        @keyframes checkmarkPop {
            0% {
                transform: scale(0);
            }
            50% {
                transform: scale(1.3);
            }
            100% {
                transform: scale(1);
            }
        }

        @keyframes progressComplete {
            0% {
                background: var(--primary-color);
            }
            50% {
                background: var(--success-color);
                box-shadow: 0 0 20px rgba(76, 175, 80, 0.5);
            }
            100% {
                background: var(--success-color);
            }
        }

        @keyframes glowPulse {
            0%, 100% {
                box-shadow: 0 0 5px rgba(76, 175, 80, 0.3);
            }
            50% {
                box-shadow: 0 0 20px rgba(76, 175, 80, 0.6);
            }
        }

        /* Result screen animations */
        .result-screen.visible {
            display: block;
            animation: fadeInUp 0.5s ease-out;
        }

        .result-screen.visible .result-icon {
            animation: successPulse 0.6s ease-out 0.2s both;
        }

        .result-screen.visible .result-title {
            animation: fadeInUp 0.4s ease-out 0.4s both;
        }

        .result-screen.visible .result-message {
            animation: fadeInUp 0.4s ease-out 0.5s both;
        }

        .result-screen.visible .control-btn {
            animation: fadeInUp 0.4s ease-out 0.6s both;
        }

        /* Failure-specific animations */
        .result-screen.failure.visible .result-icon {
            animation: failureShake 0.6s ease-out 0.2s both;
        }

        /* Indicator animations */
        .indicator.completing {
            animation: checkmarkPop 0.4s ease-out;
        }

        .indicator.completed {
            animation: glowPulse 2s ease-in-out infinite;
        }

        /* Progress bar success animation */
        .progress-fill.completing {
            animation: progressComplete 0.5s ease-out forwards;
        }

        /* Face guide success glow */
        .face-guide.success-glow {
            animation: glowPulse 1s ease-in-out;
            border-color: var(--success-color);
            box-shadow: 0 0 30px rgba(76, 175, 80, 0.4);
        }

        /* Challenge panel slide animations */
        .challenge-panel {
            transition: transform 0.3s ease-out, opacity 0.3s ease-out;
        }

        .challenge-panel.slide-out {
            transform: translateY(-20px);
            opacity: 0;
        }

        .challenge-panel.slide-in {
            animation: fadeInUp 0.3s ease-out;
        }

        /* Hidden utility class */
        .hidden {
            display: none !important;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Header -->
        <div class="header">
            <h1>Liveness Verification</h1>
            <p>Complete the challenges to verify you're a real person</p>
        </div>

        <!-- Video Container -->
        <div class="video-container">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas"></canvas>
            <div class="face-guide" id="faceGuide"></div>
            <div class="face-warning-overlay" id="faceWarningOverlay">
                <div class="warning-icon">‚ö†Ô∏è</div>
                <div class="warning-text" id="faceWarningText">No face detected</div>
            </div>
            <div class="status-overlay">
                <p class="status-text" id="statusText">Initializing camera...</p>
            </div>
        </div>

        <!-- Error Message -->
        <div class="error-message" id="errorMessage">
            <div class="error-icon" id="errorIcon">üì∑</div>
            <h3 class="error-title" id="errorTitle">Camera Access Required</h3>
            <p class="error-text" id="errorText">Camera access denied. Please allow camera access and refresh the page.</p>
            <div class="error-actions">
                <button class="error-btn error-btn-primary" id="errorRetryBtn">Try Again</button>
                <button class="error-btn error-btn-secondary" id="errorHelpBtn">How to Fix</button>
            </div>
        </div>

        <!-- Warning Toast -->
        <div class="warning-toast" id="warningToast"></div>

        <!-- Challenge Panel -->
        <div class="challenge-panel" id="challengePanel">
            <div class="challenge-header">
                <span class="challenge-title">Challenge <span id="challengeNumber">1</span> of 4</span>
                <span class="challenge-timer" id="challengeTimer">5s remaining</span>
            </div>
            <div class="challenge-instruction">
                <span class="challenge-icon" id="challengeIcon">üëÅ</span>
                <div class="challenge-text">
                    <h3 id="challengeName">Blink Your Eyes</h3>
                    <p id="challengeHint">Blink naturally 2-3 times</p>
                </div>
            </div>
            <div class="progress-container">
                <div class="progress-label">
                    <span>Hold progress</span>
                    <span id="holdPercent">0%</span>
                </div>
                <div class="progress-bar">
                    <div class="progress-fill" id="progressFill"></div>
                </div>
            </div>
            <div class="progress-indicators">
                <div class="indicator active" id="indicator1"></div>
                <div class="indicator" id="indicator2"></div>
                <div class="indicator" id="indicator3"></div>
                <div class="indicator" id="indicator4"></div>
            </div>
        </div>

        <!-- Control Button -->
        <button class="control-btn" id="controlBtn">Start Verification</button>

        <!-- Result Screen -->
        <div class="result-screen" id="resultScreen">
            <div class="result-icon" id="resultIcon">‚úì</div>
            <h2 class="result-title" id="resultTitle">Verification Complete</h2>
            <p class="result-message" id="resultMessage">You have been verified as a real person.</p>
            <button class="control-btn" id="retryBtn">Try Again</button>
        </div>
    </div>

    <!-- MediaPipe Tasks Vision - using ES modules -->
    <script type="module">
        // Import MediaPipe Tasks Vision from CDN
        import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.18/vision_bundle.min.mjs";

        // DOM Elements references
        const elements = {
            video: document.getElementById('video'),
            canvas: document.getElementById('canvas'),
            faceGuide: document.getElementById('faceGuide'),
            faceWarningOverlay: document.getElementById('faceWarningOverlay'),
            faceWarningText: document.getElementById('faceWarningText'),
            statusText: document.getElementById('statusText'),
            errorMessage: document.getElementById('errorMessage'),
            errorIcon: document.getElementById('errorIcon'),
            errorTitle: document.getElementById('errorTitle'),
            errorText: document.getElementById('errorText'),
            errorRetryBtn: document.getElementById('errorRetryBtn'),
            errorHelpBtn: document.getElementById('errorHelpBtn'),
            warningToast: document.getElementById('warningToast'),
            challengePanel: document.getElementById('challengePanel'),
            challengeNumber: document.getElementById('challengeNumber'),
            challengeTimer: document.getElementById('challengeTimer'),
            challengeIcon: document.getElementById('challengeIcon'),
            challengeName: document.getElementById('challengeName'),
            challengeHint: document.getElementById('challengeHint'),
            holdPercent: document.getElementById('holdPercent'),
            progressFill: document.getElementById('progressFill'),
            indicators: [
                document.getElementById('indicator1'),
                document.getElementById('indicator2'),
                document.getElementById('indicator3'),
                document.getElementById('indicator4')
            ],
            controlBtn: document.getElementById('controlBtn'),
            resultScreen: document.getElementById('resultScreen'),
            resultIcon: document.getElementById('resultIcon'),
            resultTitle: document.getElementById('resultTitle'),
            resultMessage: document.getElementById('resultMessage'),
            retryBtn: document.getElementById('retryBtn')
        };

        // FaceLandmarker configuration
        const FACE_LANDMARKER_MODEL_URL = 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task';

        // Global state
        let faceLandmarker = null;
        let isModelLoading = false;
        let isModelReady = false;
        let videoStream = null;
        let isCameraReady = false;

        // Detection loop state
        let isDetectionRunning = false;
        let detectionAnimationId = null;
        let lastDetectionTime = 0;
        let currentFaceResults = null;

        /**
         * Initialize FaceLandmarker with GPU delegate
         * Loads the model from CDN and configures it for face detection with blendshapes
         */
        async function initializeFaceLandmarker() {
            if (isModelLoading || isModelReady) return;

            isModelLoading = true;
            updateStatus('Loading face detection model...');

            try {
                // Load the WASM files from CDN
                const filesetResolver = await FilesetResolver.forVisionTasks(
                    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.18/wasm'
                );

                // Create FaceLandmarker with GPU delegate and blendshapes enabled
                faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: FACE_LANDMARKER_MODEL_URL,
                        delegate: 'GPU' // Use GPU for better performance
                    },
                    runningMode: 'VIDEO',
                    numFaces: 1,
                    outputFaceBlendshapes: true, // Enable blendshapes for expression detection
                    outputFacialTransformationMatrixes: true // Enable for head pose estimation
                });

                isModelReady = true;
                isModelLoading = false;
                console.log('FaceLandmarker initialized successfully with GPU delegate');

                return true;
            } catch (error) {
                isModelLoading = false;
                console.error('Failed to initialize FaceLandmarker:', error);

                // Try fallback to CPU if GPU fails
                if (error.message && error.message.includes('GPU')) {
                    console.log('GPU delegate failed, attempting CPU fallback...');
                    return await initializeFaceLandmarkerCPU();
                }

                showError(
                    'Failed to load the face detection model. This might be due to a network issue.',
                    'MODEL_LOAD_FAILED'
                );
                return false;
            }
        }

        /**
         * Fallback initialization with CPU delegate
         */
        async function initializeFaceLandmarkerCPU() {
            try {
                const filesetResolver = await FilesetResolver.forVisionTasks(
                    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.18/wasm'
                );

                faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: FACE_LANDMARKER_MODEL_URL,
                        delegate: 'CPU'
                    },
                    runningMode: 'VIDEO',
                    numFaces: 1,
                    outputFaceBlendshapes: true,
                    outputFacialTransformationMatrixes: true
                });

                isModelReady = true;
                isModelLoading = false;
                console.log('FaceLandmarker initialized with CPU delegate (fallback)');

                return true;
            } catch (error) {
                console.error('CPU fallback also failed:', error);
                showError(
                    'Failed to load the face detection model. Please try using a different browser like Chrome.',
                    'MODEL_LOAD_FAILED'
                );
                return false;
            }
        }

        /**
         * Update status text displayed to user
         */
        function updateStatus(message) {
            elements.statusText.textContent = message;
        }

        // Error types with their display configuration
        const ErrorTypes = {
            CAMERA_DENIED: {
                icon: 'üö´',
                title: 'Camera Access Denied',
                helpText: 'To enable camera access:\n1. Click the camera icon in your browser\'s address bar\n2. Select "Allow" for camera permissions\n3. Refresh the page',
                canRetry: true
            },
            CAMERA_NOT_FOUND: {
                icon: 'üì∑',
                title: 'No Camera Found',
                helpText: 'Please ensure:\n1. A camera is connected to your device\n2. Camera drivers are installed\n3. The camera isn\'t disabled in device settings',
                canRetry: true
            },
            CAMERA_IN_USE: {
                icon: '‚ö†Ô∏è',
                title: 'Camera In Use',
                helpText: 'Your camera is being used by another application.\n\nTry:\n1. Close other apps using the camera (video calls, etc.)\n2. Close other browser tabs that may be using the camera\n3. Then click Try Again',
                canRetry: true
            },
            CAMERA_ERROR: {
                icon: 'üì∑',
                title: 'Camera Error',
                helpText: 'There was a problem accessing your camera.\n\nTry:\n1. Refresh the page\n2. Restart your browser\n3. Check camera permissions in browser settings',
                canRetry: true
            },
            MODEL_LOAD_FAILED: {
                icon: 'üîÑ',
                title: 'Loading Failed',
                helpText: 'Failed to load the face detection model.\n\nTry:\n1. Check your internet connection\n2. Refresh the page\n3. Try a different browser (Chrome recommended)',
                canRetry: true
            },
            BROWSER_NOT_SUPPORTED: {
                icon: 'üåê',
                title: 'Browser Not Supported',
                helpText: 'Your browser doesn\'t support the required features.\n\nPlease use a modern browser:\n‚Ä¢ Google Chrome (recommended)\n‚Ä¢ Mozilla Firefox\n‚Ä¢ Microsoft Edge\n‚Ä¢ Safari 14+',
                canRetry: false
            },
            INITIALIZATION_TIMEOUT: {
                icon: '‚è±Ô∏è',
                title: 'Loading Timed Out',
                helpText: 'The app is taking too long to load.\n\nThis might be due to:\n1. Slow internet connection\n2. Server issues\n\nPlease try again or refresh the page.',
                canRetry: true
            }
        };

        // Current error state for retry handling
        let currentErrorType = null;

        /**
         * Show error message to user with type-specific display
         */
        function showError(message, errorType = 'CAMERA_ERROR') {
            const errorConfig = ErrorTypes[errorType] || ErrorTypes.CAMERA_ERROR;
            currentErrorType = errorType;

            elements.errorIcon.textContent = errorConfig.icon;
            elements.errorTitle.textContent = errorConfig.title;
            elements.errorText.textContent = message;
            elements.errorMessage.classList.add('visible');
            elements.controlBtn.disabled = true;

            // Show/hide retry button based on error type
            elements.errorRetryBtn.style.display = errorConfig.canRetry ? 'block' : 'none';

            // Store help text for the help button
            elements.errorHelpBtn.dataset.helpText = errorConfig.helpText;
        }

        /**
         * Hide error message
         */
        function hideError() {
            elements.errorMessage.classList.remove('visible');
            currentErrorType = null;
        }

        /**
         * Show warning toast for transient messages
         */
        function showWarningToast(message, duration = 3000) {
            elements.warningToast.textContent = message;
            elements.warningToast.classList.add('visible');

            setTimeout(() => {
                elements.warningToast.classList.remove('visible');
            }, duration);
        }

        /**
         * Show/hide face warning overlay
         */
        function showFaceWarning(message) {
            elements.faceWarningText.textContent = message;
            elements.faceWarningOverlay.classList.add('visible');
        }

        function hideFaceWarning() {
            elements.faceWarningOverlay.classList.remove('visible');
        }

        /**
         * Check browser compatibility
         */
        function checkBrowserCompatibility() {
            // Check for getUserMedia support
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                showError(
                    'Your browser doesn\'t support camera access. Please use a modern browser like Chrome, Firefox, or Edge.',
                    'BROWSER_NOT_SUPPORTED'
                );
                return false;
            }

            // Check for WebGL support (needed for MediaPipe GPU delegate)
            const canvas = document.createElement('canvas');
            const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
            if (!gl) {
                console.warn('WebGL not supported, will use CPU fallback');
            }

            return true;
        }

        /**
         * Check if FaceLandmarker is ready for detection
         */
        function isFaceLandmarkerReady() {
            return isModelReady && faceLandmarker !== null;
        }

        /**
         * Initialize WebRTC camera with getUserMedia
         * Requests camera access and sets up the video stream with mirrored view
         */
        async function initializeCamera() {
            updateStatus('Requesting camera access...');

            // Define video constraints for optimal face detection
            const constraints = {
                video: {
                    width: { ideal: 640, max: 1280 },
                    height: { ideal: 480, max: 720 },
                    facingMode: 'user', // Front-facing camera
                    frameRate: { ideal: 30, max: 60 }
                },
                audio: false
            };

            try {
                // Request camera access
                videoStream = await navigator.mediaDevices.getUserMedia(constraints);

                // Attach stream to video element
                elements.video.srcObject = videoStream;

                // Wait for video to be ready
                await new Promise((resolve, reject) => {
                    elements.video.onloadedmetadata = () => {
                        // Set canvas dimensions to match video
                        elements.canvas.width = elements.video.videoWidth;
                        elements.canvas.height = elements.video.videoHeight;
                        resolve();
                    };
                    elements.video.onerror = () => {
                        reject(new Error('Video failed to load'));
                    };
                });

                // Play the video
                await elements.video.play();

                isCameraReady = true;
                updateStatus('Camera ready');
                console.log(`Camera initialized: ${elements.video.videoWidth}x${elements.video.videoHeight}`);

                return true;
            } catch (error) {
                console.error('Camera initialization failed:', error);
                isCameraReady = false;

                // Handle specific error types with appropriate error type
                if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                    showError(
                        'Camera access was denied. Please allow camera access in your browser settings.',
                        'CAMERA_DENIED'
                    );
                } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
                    showError(
                        'No camera was found on your device. Please connect a camera and try again.',
                        'CAMERA_NOT_FOUND'
                    );
                } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
                    showError(
                        'Your camera is being used by another application. Please close other apps using the camera.',
                        'CAMERA_IN_USE'
                    );
                } else if (error.name === 'OverconstrainedError') {
                    // Try again with less strict constraints
                    console.log('Constraints too strict, retrying with basic constraints...');
                    return await initializeCameraBasic();
                } else {
                    showError(
                        `Camera error: ${error.message || 'An unknown error occurred while accessing the camera.'}`,
                        'CAMERA_ERROR'
                    );
                }

                return false;
            }
        }

        /**
         * Fallback camera initialization with basic constraints
         * Used when ideal constraints cannot be satisfied
         */
        async function initializeCameraBasic() {
            const basicConstraints = {
                video: { facingMode: 'user' },
                audio: false
            };

            try {
                videoStream = await navigator.mediaDevices.getUserMedia(basicConstraints);
                elements.video.srcObject = videoStream;

                await new Promise((resolve, reject) => {
                    elements.video.onloadedmetadata = () => {
                        elements.canvas.width = elements.video.videoWidth;
                        elements.canvas.height = elements.video.videoHeight;
                        resolve();
                    };
                    elements.video.onerror = () => reject(new Error('Video failed to load'));
                });

                await elements.video.play();

                isCameraReady = true;
                updateStatus('Camera ready (basic mode)');
                console.log(`Camera initialized (basic): ${elements.video.videoWidth}x${elements.video.videoHeight}`);

                return true;
            } catch (error) {
                console.error('Basic camera initialization also failed:', error);
                showError(
                    'Unable to access the camera. Please check your browser settings and permissions.',
                    'CAMERA_ERROR'
                );
                return false;
            }
        }

        /**
         * Stop the camera stream and release resources
         */
        function stopCamera() {
            if (videoStream) {
                videoStream.getTracks().forEach(track => {
                    track.stop();
                    console.log(`Stopped track: ${track.kind}`);
                });
                videoStream = null;
            }
            elements.video.srcObject = null;
            isCameraReady = false;
        }

        /**
         * Check if camera is ready for use
         */
        function isCameraInitialized() {
            return isCameraReady && videoStream !== null && elements.video.readyState >= 2;
        }

        /**
         * Check if both camera and model are ready
         */
        function isAppReady() {
            return isCameraInitialized() && isFaceLandmarkerReady();
        }

        /**
         * Enable the start button when both camera and model are ready
         */
        function checkAndEnableStartButton() {
            if (isAppReady()) {
                elements.controlBtn.disabled = false;
                updateStatus('Position your face in the oval and click Start');
            }
        }

        /**
         * Main detection loop using requestAnimationFrame
         * Continuously processes video frames for face detection
         */
        function detectionLoop(timestamp) {
            if (!isDetectionRunning) {
                return;
            }

            // Check if video is ready and playing
            if (!isCameraInitialized() || elements.video.paused || elements.video.ended) {
                detectionAnimationId = requestAnimationFrame(detectionLoop);
                return;
            }

            // Run face detection
            if (isFaceLandmarkerReady()) {
                try {
                    // Detect faces in the current video frame
                    // Use performance.now() for VIDEO running mode
                    const startTime = performance.now();
                    currentFaceResults = faceLandmarker.detectForVideo(elements.video, startTime);
                    lastDetectionTime = startTime;

                    // Process detection results
                    processDetectionResults(currentFaceResults);
                } catch (error) {
                    console.error('Detection error:', error);
                }
            }

            // Schedule next frame
            detectionAnimationId = requestAnimationFrame(detectionLoop);
        }

        /**
         * Process face detection results
         * Updates UI based on whether a face is detected and its position
         */
        function processDetectionResults(results) {
            const ctx = elements.canvas.getContext('2d');

            // Clear previous drawings
            ctx.clearRect(0, 0, elements.canvas.width, elements.canvas.height);

            // Process blink detection
            const blinkResult = BlinkDetector.processFrame(results);

            // Process head movement detection
            const headResult = HeadMovementDetector.processFrame(results);

            // Process expression detection
            const expressionResult = ExpressionDetector.processFrame(results);

            // Pass detection results to ChallengeManager if verification is active
            if (ChallengeManager.isActive()) {
                ChallengeManager.processFrame(results, blinkResult, headResult, expressionResult);
            }

            // Check if a face was detected
            if (results && results.faceLandmarks && results.faceLandmarks.length > 0) {
                const landmarks = results.faceLandmarks[0];
                const blendshapes = results.faceBlendshapes && results.faceBlendshapes.length > 0
                    ? results.faceBlendshapes[0].categories
                    : null;
                const transformMatrix = results.facialTransformationMatrixes && results.facialTransformationMatrixes.length > 0
                    ? results.facialTransformationMatrixes[0]
                    : null;

                // Face detected - reset no face timer and hide warning
                noFaceDetectedStartTime = null;
                hideFaceWarning();

                // Update face guide to show detected state (only when not in active challenge)
                if (!ChallengeManager.isActive()) {
                    elements.faceGuide.classList.add('detected');
                    elements.faceGuide.classList.remove('warning');

                    // Check if face is well-positioned
                    const facePosition = checkFacePosition(landmarks);
                    if (!facePosition.isWellPositioned) {
                        elements.faceGuide.classList.add('warning');
                        elements.faceGuide.classList.remove('detected');
                        updateStatus(facePosition.message);
                    } else {
                        // Show expression values for debugging/feedback
                        const smileDisplay = (expressionResult.values.smile * 100).toFixed(0);
                        const mouthDisplay = (expressionResult.values.mouthOpen * 100).toFixed(0);
                        const browDisplay = (expressionResult.values.eyebrowRaise * 100).toFixed(0);
                        const calibStatus = headResult.isCalibrated ? '' : ' (calibrating...)';
                        updateStatus(`Smile: ${smileDisplay}% | Mouth: ${mouthDisplay}% | Brow: ${browDisplay}%${calibStatus}`);
                    }
                }

                // Draw face landmarks on canvas (mirrored to match video)
                drawFaceLandmarks(ctx, landmarks);
            } else {
                // No face detected
                const now = performance.now();

                // Track how long no face has been detected
                if (noFaceDetectedStartTime === null) {
                    noFaceDetectedStartTime = now;
                }

                const noFaceDuration = now - noFaceDetectedStartTime;

                if (!ChallengeManager.isActive()) {
                    elements.faceGuide.classList.remove('detected');
                    elements.faceGuide.classList.remove('warning');
                    updateStatus('No face detected - Position your face in the oval');

                    // Show warning overlay after extended period of no face detection
                    if (noFaceDuration > NO_FACE_WARNING_DELAY) {
                        showFaceWarning('No face detected');
                    }
                } else {
                    // During active challenge, show more urgent warning
                    showFaceWarning('Face lost - Look at the camera');
                }

                currentFaceResults = null;
            }
        }

        /**
         * Check if the face is well-positioned within the guide oval
         * Returns position status and guidance message
         */
        function checkFacePosition(landmarks) {
            // Get face bounding box from landmarks
            // Nose tip (landmark 1) as center reference
            const noseTip = landmarks[1];

            // Calculate face bounds
            let minX = 1, maxX = 0, minY = 1, maxY = 0;
            landmarks.forEach(point => {
                minX = Math.min(minX, point.x);
                maxX = Math.max(maxX, point.x);
                minY = Math.min(minY, point.y);
                maxY = Math.max(maxY, point.y);
            });

            const faceWidth = maxX - minX;
            const faceHeight = maxY - minY;
            const faceCenterX = (minX + maxX) / 2;
            const faceCenterY = (minY + maxY) / 2;

            // Define acceptable ranges (normalized 0-1)
            const centerTolerance = 0.15;
            const minFaceSize = 0.25;
            const maxFaceSize = 0.75;

            // Check horizontal centering (note: x is mirrored)
            if (Math.abs(faceCenterX - 0.5) > centerTolerance) {
                const direction = faceCenterX < 0.5 ? 'right' : 'left';
                return { isWellPositioned: false, message: `Move your face ${direction}` };
            }

            // Check vertical centering
            if (Math.abs(faceCenterY - 0.5) > centerTolerance) {
                const direction = faceCenterY < 0.5 ? 'down' : 'up';
                return { isWellPositioned: false, message: `Move your face ${direction}` };
            }

            // Check face size (too far or too close)
            if (faceWidth < minFaceSize || faceHeight < minFaceSize) {
                return { isWellPositioned: false, message: 'Move closer to the camera' };
            }

            if (faceWidth > maxFaceSize || faceHeight > maxFaceSize) {
                return { isWellPositioned: false, message: 'Move further from the camera' };
            }

            return { isWellPositioned: true, message: 'Face detected - Ready' };
        }

        /**
         * Draw face landmarks on the canvas
         * Draws contours for face mesh visualization with feature highlighting
         */
        function drawFaceLandmarks(ctx, landmarks) {
            const width = elements.canvas.width;
            const height = elements.canvas.height;

            // Save context state
            ctx.save();

            // Mirror the canvas to match the mirrored video
            ctx.translate(width, 0);
            ctx.scale(-1, 1);

            // Get current challenge for feature highlighting
            const currentChallenge = ChallengeManager.getCurrentChallenge();
            const challengeState = ChallengeManager.getCurrentState();
            const isDetecting = challengeState === ChallengeManager.States.DETECTING;

            // Define all facial contours with their styles
            const contourDefinitions = {
                // Face oval - subtle outline
                faceOval: {
                    indices: [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109, 10],
                    baseColor: 'rgba(74, 144, 217, 0.4)',
                    highlightColor: 'rgba(76, 175, 80, 0.8)',
                    lineWidth: 2,
                    highlightOn: ['turn_left', 'turn_right', 'look_up', 'look_down']
                },
                // Left eyebrow
                leftEyebrow: {
                    indices: [276, 283, 282, 295, 285, 300, 293, 334, 296, 336],
                    baseColor: 'rgba(74, 144, 217, 0.5)',
                    highlightColor: 'rgba(255, 193, 7, 0.9)',
                    lineWidth: 2,
                    highlightOn: ['raise_eyebrows']
                },
                // Right eyebrow
                rightEyebrow: {
                    indices: [46, 53, 52, 65, 55, 70, 63, 105, 66, 107],
                    baseColor: 'rgba(74, 144, 217, 0.5)',
                    highlightColor: 'rgba(255, 193, 7, 0.9)',
                    lineWidth: 2,
                    highlightOn: ['raise_eyebrows']
                },
                // Left eye outer
                leftEye: {
                    indices: [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246, 33],
                    baseColor: 'rgba(74, 144, 217, 0.6)',
                    highlightColor: 'rgba(33, 150, 243, 0.9)',
                    lineWidth: 2,
                    highlightOn: ['blink']
                },
                // Right eye outer
                rightEye: {
                    indices: [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398, 362],
                    baseColor: 'rgba(74, 144, 217, 0.6)',
                    highlightColor: 'rgba(33, 150, 243, 0.9)',
                    lineWidth: 2,
                    highlightOn: ['blink']
                },
                // Left iris (approximate circle)
                leftIris: {
                    indices: [468, 469, 470, 471, 472],
                    baseColor: 'rgba(74, 144, 217, 0.3)',
                    highlightColor: 'rgba(33, 150, 243, 0.7)',
                    lineWidth: 1,
                    highlightOn: ['blink'],
                    isIris: true
                },
                // Right iris (approximate circle)
                rightIris: {
                    indices: [473, 474, 475, 476, 477],
                    baseColor: 'rgba(74, 144, 217, 0.3)',
                    highlightColor: 'rgba(33, 150, 243, 0.7)',
                    lineWidth: 1,
                    highlightOn: ['blink'],
                    isIris: true
                },
                // Nose bridge
                noseBridge: {
                    indices: [168, 6, 197, 195, 5, 4, 1],
                    baseColor: 'rgba(74, 144, 217, 0.4)',
                    highlightColor: 'rgba(76, 175, 80, 0.7)',
                    lineWidth: 1.5,
                    highlightOn: ['turn_left', 'turn_right', 'look_up', 'look_down']
                },
                // Nose bottom
                noseBottom: {
                    indices: [98, 97, 2, 326, 327],
                    baseColor: 'rgba(74, 144, 217, 0.4)',
                    highlightColor: 'rgba(76, 175, 80, 0.7)',
                    lineWidth: 1.5,
                    highlightOn: ['turn_left', 'turn_right', 'look_up', 'look_down']
                },
                // Lips outer
                lipsOuter: {
                    indices: [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 409, 270, 269, 267, 0, 37, 39, 40, 185, 61],
                    baseColor: 'rgba(74, 144, 217, 0.5)',
                    highlightColor: 'rgba(233, 30, 99, 0.9)',
                    lineWidth: 2,
                    highlightOn: ['smile', 'open_mouth']
                },
                // Lips inner
                lipsInner: {
                    indices: [78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308, 415, 310, 311, 312, 13, 82, 81, 80, 191, 78],
                    baseColor: 'rgba(74, 144, 217, 0.3)',
                    highlightColor: 'rgba(233, 30, 99, 0.7)',
                    lineWidth: 1.5,
                    highlightOn: ['smile', 'open_mouth']
                }
            };

            // Helper function to draw a contour path
            function drawContourPath(indices, color, lineWidth, filled = false) {
                ctx.beginPath();
                indices.forEach((index, i) => {
                    if (index >= landmarks.length) return;
                    const point = landmarks[index];
                    const x = point.x * width;
                    const y = point.y * height;
                    if (i === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }
                });
                ctx.strokeStyle = color;
                ctx.lineWidth = lineWidth;
                ctx.lineCap = 'round';
                ctx.lineJoin = 'round';
                ctx.stroke();
                if (filled) {
                    ctx.fillStyle = color.replace(/[\d.]+\)$/, '0.2)');
                    ctx.fill();
                }
            }

            // Helper function to draw iris as a filled circle
            function drawIris(indices, color) {
                if (indices.length === 0 || indices[0] >= landmarks.length) return;

                // Calculate center from iris landmarks
                let centerX = 0, centerY = 0;
                let validPoints = 0;
                indices.forEach(index => {
                    if (index < landmarks.length) {
                        centerX += landmarks[index].x;
                        centerY += landmarks[index].y;
                        validPoints++;
                    }
                });
                if (validPoints === 0) return;

                centerX = (centerX / validPoints) * width;
                centerY = (centerY / validPoints) * height;

                // Draw iris circle
                const radius = 6;
                ctx.beginPath();
                ctx.arc(centerX, centerY, radius, 0, Math.PI * 2);
                ctx.fillStyle = color;
                ctx.fill();
            }

            // Draw each contour with appropriate highlighting
            Object.entries(contourDefinitions).forEach(([name, contour]) => {
                // Determine if this feature should be highlighted
                let shouldHighlight = false;
                if (isDetecting && currentChallenge && contour.highlightOn) {
                    shouldHighlight = contour.highlightOn.includes(currentChallenge.id);
                }

                const color = shouldHighlight ? contour.highlightColor : contour.baseColor;
                const lineWidth = shouldHighlight ? contour.lineWidth * 1.5 : contour.lineWidth;

                if (contour.isIris) {
                    drawIris(contour.indices, color);
                } else {
                    const shouldFill = shouldHighlight && (name.includes('Eye') || name.includes('lips'));
                    drawContourPath(contour.indices, color, lineWidth, shouldFill);
                }
            });

            // Draw key landmark points for nose and mouth corners
            const keyPoints = [
                { index: 1, size: 4, baseColor: 'rgba(74, 144, 217, 0.7)', highlight: ['turn_left', 'turn_right', 'look_up', 'look_down'] }, // Nose tip
                { index: 4, size: 3, baseColor: 'rgba(74, 144, 217, 0.5)', highlight: ['turn_left', 'turn_right', 'look_up', 'look_down'] }, // Nose bridge
                { index: 61, size: 3, baseColor: 'rgba(74, 144, 217, 0.6)', highlight: ['smile', 'open_mouth'] }, // Left mouth corner
                { index: 291, size: 3, baseColor: 'rgba(74, 144, 217, 0.6)', highlight: ['smile', 'open_mouth'] }, // Right mouth corner
                { index: 33, size: 3, baseColor: 'rgba(74, 144, 217, 0.6)', highlight: ['blink'] }, // Left eye outer
                { index: 133, size: 3, baseColor: 'rgba(74, 144, 217, 0.6)', highlight: ['blink'] }, // Left eye inner
                { index: 362, size: 3, baseColor: 'rgba(74, 144, 217, 0.6)', highlight: ['blink'] }, // Right eye outer
                { index: 263, size: 3, baseColor: 'rgba(74, 144, 217, 0.6)', highlight: ['blink'] }  // Right eye inner
            ];

            keyPoints.forEach(({ index, size, baseColor, highlight }) => {
                if (index >= landmarks.length) return;

                let shouldHighlight = false;
                if (isDetecting && currentChallenge && highlight) {
                    shouldHighlight = highlight.includes(currentChallenge.id);
                }

                const color = shouldHighlight ? 'rgba(76, 175, 80, 0.9)' : baseColor;
                const pointSize = shouldHighlight ? size * 1.5 : size;

                const point = landmarks[index];
                const x = point.x * width;
                const y = point.y * height;

                ctx.beginPath();
                ctx.arc(x, y, pointSize, 0, Math.PI * 2);
                ctx.fillStyle = color;
                ctx.fill();

                // Add glow effect for highlighted points
                if (shouldHighlight) {
                    ctx.beginPath();
                    ctx.arc(x, y, pointSize * 2, 0, Math.PI * 2);
                    ctx.fillStyle = color.replace(/[\d.]+\)$/, '0.2)');
                    ctx.fill();
                }
            });

            // Draw direction indicator for head movement challenges
            if (isDetecting && currentChallenge) {
                const headAngles = HeadMovementDetector.getCurrentAngles();
                const baseline = HeadMovementDetector.getBaseline();

                if (currentChallenge.detector === 'head' && headAngles && baseline) {
                    const noseTip = landmarks[1];
                    const centerX = noseTip.x * width;
                    const centerY = noseTip.y * height;

                    // Draw direction arrow based on challenge
                    ctx.strokeStyle = 'rgba(76, 175, 80, 0.8)';
                    ctx.lineWidth = 3;
                    ctx.lineCap = 'round';

                    const arrowLength = 30;
                    let endX = centerX, endY = centerY;

                    switch (currentChallenge.direction) {
                        case 'left':
                            endX = centerX + arrowLength; // Mirrored
                            break;
                        case 'right':
                            endX = centerX - arrowLength; // Mirrored
                            break;
                        case 'up':
                            endY = centerY - arrowLength;
                            break;
                        case 'down':
                            endY = centerY + arrowLength;
                            break;
                    }

                    // Draw arrow line
                    ctx.beginPath();
                    ctx.moveTo(centerX, centerY);
                    ctx.lineTo(endX, endY);
                    ctx.stroke();

                    // Draw arrowhead
                    const angle = Math.atan2(endY - centerY, endX - centerX);
                    const headLength = 10;
                    ctx.beginPath();
                    ctx.moveTo(endX, endY);
                    ctx.lineTo(endX - headLength * Math.cos(angle - Math.PI / 6), endY - headLength * Math.sin(angle - Math.PI / 6));
                    ctx.moveTo(endX, endY);
                    ctx.lineTo(endX - headLength * Math.cos(angle + Math.PI / 6), endY - headLength * Math.sin(angle + Math.PI / 6));
                    ctx.stroke();
                }
            }

            // Restore context state
            ctx.restore();
        }

        /**
         * Start the detection loop
         */
        function startDetectionLoop() {
            if (isDetectionRunning) {
                console.log('Detection loop already running');
                return;
            }

            if (!isAppReady()) {
                console.error('Cannot start detection: app not ready');
                return;
            }

            isDetectionRunning = true;
            console.log('Starting detection loop');
            detectionAnimationId = requestAnimationFrame(detectionLoop);
        }

        /**
         * Stop the detection loop
         */
        function stopDetectionLoop() {
            isDetectionRunning = false;

            if (detectionAnimationId) {
                cancelAnimationFrame(detectionAnimationId);
                detectionAnimationId = null;
            }

            // Clear canvas
            const ctx = elements.canvas.getContext('2d');
            ctx.clearRect(0, 0, elements.canvas.width, elements.canvas.height);

            console.log('Detection loop stopped');
        }

        /**
         * Get the current face detection results
         * Used by other modules (BlinkDetector, HeadMovementDetector, etc.)
         */
        function getCurrentFaceResults() {
            return currentFaceResults;
        }

        /**
         * Check if detection is currently running
         */
        function isDetectionActive() {
            return isDetectionRunning;
        }

        // =====================================================
        // BLINK DETECTOR MODULE
        // Detects blinks using Eye Aspect Ratio (EAR) and blendshapes
        // =====================================================

        const BlinkDetector = (function() {
            // Configuration
            const config = {
                // EAR threshold - below this value indicates a blink
                earThreshold: 0.21,
                // Blendshape threshold - above this value indicates a blink
                blendshapeThreshold: 0.5,
                // Minimum consecutive frames to confirm a blink
                minConsecutiveFrames: 2,
                // Minimum time between blinks (ms) to avoid double-counting
                minTimeBetweenBlinks: 150,
                // Maximum blink duration (ms) - longer than this is considered eyes closed
                maxBlinkDuration: 500
            };

            // State
            let state = {
                isBlinking: false,
                blinkStartTime: null,
                consecutiveBlinkFrames: 0,
                lastBlinkTime: 0,
                blinkCount: 0,
                currentEAR: { left: 1, right: 1, average: 1 },
                currentBlendshapes: { left: 0, right: 0 }
            };

            // Eye landmark indices for EAR calculation
            // Based on MediaPipe Face Mesh 478 landmarks
            const eyeIndices = {
                // Left eye landmarks (from viewer's perspective, which is right eye anatomically)
                leftEye: {
                    // Vertical landmarks (top to bottom)
                    top: [159, 158, 157],      // Upper eyelid
                    bottom: [145, 144, 163],   // Lower eyelid
                    // Horizontal landmarks (inner to outer)
                    inner: 133,
                    outer: 33
                },
                // Right eye landmarks (from viewer's perspective, which is left eye anatomically)
                rightEye: {
                    top: [386, 385, 384],      // Upper eyelid
                    bottom: [374, 373, 380],   // Lower eyelid
                    inner: 362,
                    outer: 263
                }
            };

            /**
             * Calculate Eye Aspect Ratio (EAR) for one eye
             * EAR = (|p2-p6| + |p3-p5|) / (2 * |p1-p4|)
             * where p1-p6 are the eye landmark points
             */
            function calculateEAR(landmarks, eyeConfig) {
                // Get landmark points
                const top = eyeConfig.top.map(i => landmarks[i]);
                const bottom = eyeConfig.bottom.map(i => landmarks[i]);
                const inner = landmarks[eyeConfig.inner];
                const outer = landmarks[eyeConfig.outer];

                // Calculate vertical distances (average of 3 pairs)
                let verticalSum = 0;
                for (let i = 0; i < 3; i++) {
                    verticalSum += distance3D(top[i], bottom[i]);
                }
                const avgVertical = verticalSum / 3;

                // Calculate horizontal distance
                const horizontal = distance3D(inner, outer);

                // Calculate EAR
                if (horizontal === 0) return 1; // Avoid division by zero
                return avgVertical / horizontal;
            }

            /**
             * Calculate 3D Euclidean distance between two landmark points
             */
            function distance3D(p1, p2) {
                const dx = p1.x - p2.x;
                const dy = p1.y - p2.y;
                const dz = (p1.z || 0) - (p2.z || 0);
                return Math.sqrt(dx * dx + dy * dy + dz * dz);
            }

            /**
             * Get blink blendshape values from face detection results
             */
            function getBlinkBlendshapes(blendshapes) {
                if (!blendshapes || !Array.isArray(blendshapes)) {
                    return { left: 0, right: 0 };
                }

                let leftBlink = 0;
                let rightBlink = 0;

                // Find eyeBlink blendshapes in the categories array
                for (const shape of blendshapes) {
                    if (shape.categoryName === 'eyeBlinkLeft') {
                        leftBlink = shape.score;
                    } else if (shape.categoryName === 'eyeBlinkRight') {
                        rightBlink = shape.score;
                    }
                }

                return { left: leftBlink, right: rightBlink };
            }

            /**
             * Check if a blink is detected using both EAR and blendshapes
             * Returns true if either method detects a blink
             */
            function isBlinkDetected(earLeft, earRight, blendshapeLeft, blendshapeRight) {
                // Check EAR method
                const earAvg = (earLeft + earRight) / 2;
                const earBlink = earAvg < config.earThreshold;

                // Check blendshape method
                const blendshapeBlink = blendshapeLeft > config.blendshapeThreshold ||
                                       blendshapeRight > config.blendshapeThreshold;

                return earBlink || blendshapeBlink;
            }

            /**
             * Process a frame and detect blinks
             * Call this function every frame with the current face results
             * @param {Object} faceResults - Results from FaceLandmarker.detectForVideo()
             * @returns {Object} Detection result with blink status and metrics
             */
            function processFrame(faceResults) {
                const now = performance.now();

                // Default result
                const result = {
                    blinkDetected: false,
                    isCurrentlyBlinking: false,
                    blinkCount: state.blinkCount,
                    ear: state.currentEAR,
                    blendshapes: state.currentBlendshapes,
                    confidence: 0
                };

                // Check if we have valid face data
                if (!faceResults || !faceResults.faceLandmarks || faceResults.faceLandmarks.length === 0) {
                    // Reset state when no face detected
                    state.isBlinking = false;
                    state.consecutiveBlinkFrames = 0;
                    state.blinkStartTime = null;
                    return result;
                }

                const landmarks = faceResults.faceLandmarks[0];
                const blendshapes = faceResults.faceBlendshapes && faceResults.faceBlendshapes.length > 0
                    ? faceResults.faceBlendshapes[0].categories
                    : null;

                // Calculate EAR for both eyes
                const earLeft = calculateEAR(landmarks, eyeIndices.leftEye);
                const earRight = calculateEAR(landmarks, eyeIndices.rightEye);
                const earAvg = (earLeft + earRight) / 2;

                // Get blendshape values
                const blendshapeValues = getBlinkBlendshapes(blendshapes);

                // Update current values
                state.currentEAR = { left: earLeft, right: earRight, average: earAvg };
                state.currentBlendshapes = blendshapeValues;
                result.ear = state.currentEAR;
                result.blendshapes = state.currentBlendshapes;

                // Check if blink is detected this frame
                const blinkThisFrame = isBlinkDetected(
                    earLeft, earRight,
                    blendshapeValues.left, blendshapeValues.right
                );

                result.isCurrentlyBlinking = blinkThisFrame;

                if (blinkThisFrame) {
                    state.consecutiveBlinkFrames++;

                    // Start tracking blink time
                    if (!state.blinkStartTime) {
                        state.blinkStartTime = now;
                    }

                    // Calculate confidence based on how strongly the blink is detected
                    const earConfidence = Math.max(0, 1 - (earAvg / config.earThreshold));
                    const blendshapeConfidence = Math.max(blendshapeValues.left, blendshapeValues.right);
                    result.confidence = Math.max(earConfidence, blendshapeConfidence);

                    // Check if we've reached the minimum consecutive frames
                    if (state.consecutiveBlinkFrames >= config.minConsecutiveFrames && !state.isBlinking) {
                        // Check if enough time has passed since last blink
                        if (now - state.lastBlinkTime > config.minTimeBetweenBlinks) {
                            state.isBlinking = true;
                        }
                    }
                } else {
                    // Eyes are open now
                    if (state.isBlinking) {
                        // Blink just ended - check if it was a valid blink duration
                        const blinkDuration = now - (state.blinkStartTime || now);

                        if (blinkDuration < config.maxBlinkDuration) {
                            // Valid blink completed
                            state.blinkCount++;
                            state.lastBlinkTime = now;
                            result.blinkDetected = true;
                            result.blinkCount = state.blinkCount;
                            console.log(`Blink detected! Count: ${state.blinkCount}, Duration: ${blinkDuration.toFixed(0)}ms`);
                        }
                    }

                    // Reset blink tracking
                    state.isBlinking = false;
                    state.consecutiveBlinkFrames = 0;
                    state.blinkStartTime = null;
                }

                return result;
            }

            /**
             * Reset the blink detector state
             * Call this when starting a new challenge
             */
            function reset() {
                state = {
                    isBlinking: false,
                    blinkStartTime: null,
                    consecutiveBlinkFrames: 0,
                    lastBlinkTime: 0,
                    blinkCount: 0,
                    currentEAR: { left: 1, right: 1, average: 1 },
                    currentBlendshapes: { left: 0, right: 0 }
                };
                console.log('BlinkDetector reset');
            }

            /**
             * Get the current blink count
             */
            function getBlinkCount() {
                return state.blinkCount;
            }

            /**
             * Get the current EAR values
             */
            function getCurrentEAR() {
                return state.currentEAR;
            }

            /**
             * Get the current blendshape values
             */
            function getCurrentBlendshapes() {
                return state.currentBlendshapes;
            }

            /**
             * Check if currently in a blink
             */
            function isCurrentlyBlinking() {
                return state.isBlinking;
            }

            /**
             * Update configuration
             */
            function setConfig(newConfig) {
                Object.assign(config, newConfig);
            }

            /**
             * Get current configuration
             */
            function getConfig() {
                return { ...config };
            }

            // Public API
            return {
                processFrame,
                reset,
                getBlinkCount,
                getCurrentEAR,
                getCurrentBlendshapes,
                isCurrentlyBlinking,
                setConfig,
                getConfig
            };
        })();

        // =====================================================
        // HEAD MOVEMENT DETECTOR MODULE
        // Detects head yaw (left/right) and pitch (up/down) movements
        // Uses nose tip position relative to eye positions for calculation
        // =====================================================

        const HeadMovementDetector = (function() {
            // Configuration
            const config = {
                // Yaw threshold in degrees - head must turn this much from baseline
                yawThreshold: 10,
                // Pitch threshold in degrees - head must tilt this much from baseline
                pitchThreshold: 8,
                // Hold duration required in milliseconds
                holdDuration: 500,
                // Smoothing factor for angle calculations (0-1, higher = more responsive)
                smoothingFactor: 0.6,
                // Number of frames to establish baseline
                calibrationFrames: 20,
                // Maximum allowed deviation during hold (degrees)
                holdTolerance: 5
            };

            // State
            let state = {
                // Baseline values (established during calibration)
                baseline: {
                    yaw: 0,
                    pitch: 0,
                    isCalibrated: false,
                    calibrationSamples: []
                },
                // Current smoothed values
                currentYaw: 0,
                currentPitch: 0,
                // Raw values (before smoothing)
                rawYaw: 0,
                rawPitch: 0,
                // Hold tracking
                holdStartTime: null,
                holdDirection: null, // 'left', 'right', 'up', 'down'
                holdProgress: 0,
                // Detection results
                lastDetectedMovement: null,
                movementHistory: []
            };

            // Key landmark indices for head pose estimation
            const landmarks = {
                noseTip: 1,
                noseBridge: 6,
                leftEyeInner: 133,
                leftEyeOuter: 33,
                rightEyeInner: 362,
                rightEyeOuter: 263,
                leftEyeCenter: 468,  // Iris center (if available)
                rightEyeCenter: 473, // Iris center (if available)
                foreheadCenter: 10,
                chin: 152
            };

            /**
             * Calculate yaw angle (left/right rotation) from landmarks
             * Uses the horizontal offset of nose tip relative to eye midpoint
             */
            function calculateYaw(faceLandmarks) {
                const noseTip = faceLandmarks[landmarks.noseTip];
                const leftEye = faceLandmarks[landmarks.leftEyeInner];
                const rightEye = faceLandmarks[landmarks.rightEyeInner];

                // Calculate eye midpoint
                const eyeMidpoint = {
                    x: (leftEye.x + rightEye.x) / 2,
                    y: (leftEye.y + rightEye.y) / 2,
                    z: ((leftEye.z || 0) + (rightEye.z || 0)) / 2
                };

                // Calculate eye width for normalization
                const eyeWidth = Math.abs(leftEye.x - rightEye.x);
                if (eyeWidth === 0) return 0;

                // Calculate horizontal offset of nose from eye midpoint
                const noseOffset = noseTip.x - eyeMidpoint.x;

                // Normalize by eye width and convert to approximate degrees
                // A rough approximation: full eye width offset ‚âà 45 degrees
                const normalizedOffset = noseOffset / eyeWidth;
                const yawDegrees = normalizedOffset * 45;

                // Also factor in z-depth difference if available
                const depthDiff = (noseTip.z || 0) - eyeMidpoint.z;
                const depthFactor = depthDiff * 30; // Add depth contribution

                return yawDegrees + depthFactor;
            }

            /**
             * Calculate pitch angle (up/down tilt) from landmarks
             * Uses vertical positioning of nose tip relative to eyes and forehead
             */
            function calculatePitch(faceLandmarks) {
                const noseTip = faceLandmarks[landmarks.noseTip];
                const noseBridge = faceLandmarks[landmarks.noseBridge];
                const forehead = faceLandmarks[landmarks.foreheadCenter];
                const chin = faceLandmarks[landmarks.chin];

                // Calculate face height for normalization
                const faceHeight = Math.abs(forehead.y - chin.y);
                if (faceHeight === 0) return 0;

                // Calculate the vertical ratio of nose tip position
                // between nose bridge and chin
                const noseVerticalRange = chin.y - noseBridge.y;
                if (noseVerticalRange === 0) return 0;

                const nosePosition = (noseTip.y - noseBridge.y) / noseVerticalRange;

                // Expected position is around 0.5 when looking straight
                // Higher value = looking down, Lower value = looking up
                const expectedPosition = 0.5;
                const deviation = nosePosition - expectedPosition;

                // Convert to approximate degrees (full range ‚âà 60 degrees)
                let pitchDegrees = deviation * 60;

                // Also use z-depth as additional signal
                const zDiff = (noseTip.z || 0) - (noseBridge.z || 0);
                // When looking down, nose tip z increases relative to bridge
                pitchDegrees += zDiff * 20;

                return pitchDegrees;
            }

            /**
             * Apply exponential smoothing to reduce noise
             */
            function smoothValue(currentSmoothed, newRaw, factor) {
                return currentSmoothed * (1 - factor) + newRaw * factor;
            }

            /**
             * Determine which direction the head is turned/tilted
             */
            function getMovementDirection(yaw, pitch, baseline) {
                const yawDelta = yaw - baseline.yaw;
                const pitchDelta = pitch - baseline.pitch;

                // Check yaw (left/right)
                if (Math.abs(yawDelta) >= config.yawThreshold) {
                    // Positive yaw = turned right (nose points to viewer's left due to mirroring)
                    return yawDelta > 0 ? 'right' : 'left';
                }

                // Check pitch (up/down)
                if (Math.abs(pitchDelta) >= config.pitchThreshold) {
                    // Positive pitch = looking down
                    return pitchDelta > 0 ? 'down' : 'up';
                }

                return null;
            }

            /**
             * Check if the current angle is within tolerance of the hold angle
             */
            function isHoldingPosition(currentDirection, yaw, pitch, baseline) {
                const yawDelta = yaw - baseline.yaw;
                const pitchDelta = pitch - baseline.pitch;

                switch (currentDirection) {
                    case 'left':
                        return yawDelta <= -config.yawThreshold + config.holdTolerance;
                    case 'right':
                        return yawDelta >= config.yawThreshold - config.holdTolerance;
                    case 'up':
                        return pitchDelta <= -config.pitchThreshold + config.holdTolerance;
                    case 'down':
                        return pitchDelta >= config.pitchThreshold - config.holdTolerance;
                    default:
                        return false;
                }
            }

            /**
             * Process a frame and detect head movements
             * @param {Object} faceResults - Results from FaceLandmarker.detectForVideo()
             * @returns {Object} Detection result with movement status and metrics
             */
            function processFrame(faceResults) {
                const now = performance.now();

                // Default result
                const result = {
                    isCalibrated: state.baseline.isCalibrated,
                    currentYaw: state.currentYaw,
                    currentPitch: state.currentPitch,
                    yawFromBaseline: 0,
                    pitchFromBaseline: 0,
                    direction: null,
                    isHolding: false,
                    holdProgress: 0,
                    movementDetected: false,
                    detectedDirection: null
                };

                // Check if we have valid face data
                if (!faceResults || !faceResults.faceLandmarks || faceResults.faceLandmarks.length === 0) {
                    // Reset hold state when no face detected
                    state.holdStartTime = null;
                    state.holdDirection = null;
                    state.holdProgress = 0;
                    return result;
                }

                const faceLandmarks = faceResults.faceLandmarks[0];

                // Calculate raw yaw and pitch
                state.rawYaw = calculateYaw(faceLandmarks);
                state.rawPitch = calculatePitch(faceLandmarks);

                // Apply smoothing
                state.currentYaw = smoothValue(state.currentYaw, state.rawYaw, config.smoothingFactor);
                state.currentPitch = smoothValue(state.currentPitch, state.rawPitch, config.smoothingFactor);

                result.currentYaw = state.currentYaw;
                result.currentPitch = state.currentPitch;

                // Handle calibration
                if (!state.baseline.isCalibrated) {
                    state.baseline.calibrationSamples.push({
                        yaw: state.currentYaw,
                        pitch: state.currentPitch
                    });

                    if (state.baseline.calibrationSamples.length >= config.calibrationFrames) {
                        // Calculate average baseline from samples
                        const samples = state.baseline.calibrationSamples;
                        state.baseline.yaw = samples.reduce((sum, s) => sum + s.yaw, 0) / samples.length;
                        state.baseline.pitch = samples.reduce((sum, s) => sum + s.pitch, 0) / samples.length;
                        state.baseline.isCalibrated = true;
                        console.log(`HeadMovementDetector calibrated - Baseline: yaw=${state.baseline.yaw.toFixed(1)}¬∞, pitch=${state.baseline.pitch.toFixed(1)}¬∞`);
                    }

                    result.isCalibrated = state.baseline.isCalibrated;
                    return result;
                }

                // Calculate deltas from baseline
                result.yawFromBaseline = state.currentYaw - state.baseline.yaw;
                result.pitchFromBaseline = state.currentPitch - state.baseline.pitch;
                result.isCalibrated = true;

                // Determine current movement direction
                const direction = getMovementDirection(state.currentYaw, state.currentPitch, state.baseline);
                result.direction = direction;

                // Handle hold detection
                if (direction) {
                    if (state.holdDirection === direction) {
                        // Continue holding same direction
                        if (isHoldingPosition(direction, state.currentYaw, state.currentPitch, state.baseline)) {
                            const holdTime = now - state.holdStartTime;
                            state.holdProgress = Math.min(holdTime / config.holdDuration, 1);
                            result.holdProgress = state.holdProgress;
                            result.isHolding = true;

                            // Check if hold is complete
                            if (holdTime >= config.holdDuration) {
                                result.movementDetected = true;
                                result.detectedDirection = direction;
                                state.lastDetectedMovement = direction;
                                state.movementHistory.push({
                                    direction: direction,
                                    timestamp: now
                                });
                                console.log(`Head movement detected: ${direction} (held for ${config.holdDuration}ms)`);

                                // Reset hold to allow detecting again
                                state.holdStartTime = null;
                                state.holdDirection = null;
                                state.holdProgress = 0;
                            }
                        } else {
                            // Position drifted out of tolerance - reset
                            state.holdStartTime = now;
                            state.holdProgress = 0;
                        }
                    } else {
                        // New direction - start new hold
                        state.holdDirection = direction;
                        state.holdStartTime = now;
                        state.holdProgress = 0;
                    }
                } else {
                    // No significant movement - reset hold state
                    state.holdStartTime = null;
                    state.holdDirection = null;
                    state.holdProgress = 0;
                }

                return result;
            }

            /**
             * Reset the detector state (but keep calibration)
             */
            function reset() {
                state.holdStartTime = null;
                state.holdDirection = null;
                state.holdProgress = 0;
                state.lastDetectedMovement = null;
                state.movementHistory = [];
                console.log('HeadMovementDetector reset (calibration preserved)');
            }

            /**
             * Full reset including calibration
             */
            function resetCalibration() {
                state = {
                    baseline: {
                        yaw: 0,
                        pitch: 0,
                        isCalibrated: false,
                        calibrationSamples: []
                    },
                    currentYaw: 0,
                    currentPitch: 0,
                    rawYaw: 0,
                    rawPitch: 0,
                    holdStartTime: null,
                    holdDirection: null,
                    holdProgress: 0,
                    lastDetectedMovement: null,
                    movementHistory: []
                };
                console.log('HeadMovementDetector full reset (calibration cleared)');
            }

            /**
             * Manually set baseline to current position
             */
            function calibrate() {
                state.baseline.yaw = state.currentYaw;
                state.baseline.pitch = state.currentPitch;
                state.baseline.isCalibrated = true;
                state.baseline.calibrationSamples = [];
                console.log(`HeadMovementDetector manually calibrated - yaw=${state.baseline.yaw.toFixed(1)}¬∞, pitch=${state.baseline.pitch.toFixed(1)}¬∞`);
            }

            /**
             * Check if calibration is complete
             */
            function isCalibrated() {
                return state.baseline.isCalibrated;
            }

            /**
             * Get current yaw and pitch values
             */
            function getCurrentAngles() {
                return {
                    yaw: state.currentYaw,
                    pitch: state.currentPitch,
                    yawFromBaseline: state.currentYaw - state.baseline.yaw,
                    pitchFromBaseline: state.currentPitch - state.baseline.pitch
                };
            }

            /**
             * Get the baseline values
             */
            function getBaseline() {
                return {
                    yaw: state.baseline.yaw,
                    pitch: state.baseline.pitch,
                    isCalibrated: state.baseline.isCalibrated
                };
            }

            /**
             * Get current hold progress (0-1)
             */
            function getHoldProgress() {
                return state.holdProgress;
            }

            /**
             * Get the current hold direction
             */
            function getHoldDirection() {
                return state.holdDirection;
            }

            /**
             * Get movement history
             */
            function getMovementHistory() {
                return [...state.movementHistory];
            }

            /**
             * Update configuration
             */
            function setConfig(newConfig) {
                Object.assign(config, newConfig);
            }

            /**
             * Get current configuration
             */
            function getConfig() {
                return { ...config };
            }

            // Public API
            return {
                processFrame,
                reset,
                resetCalibration,
                calibrate,
                isCalibrated,
                getCurrentAngles,
                getBaseline,
                getHoldProgress,
                getHoldDirection,
                getMovementHistory,
                setConfig,
                getConfig
            };
        })();

        // =====================================================
        // EXPRESSION DETECTOR MODULE
        // Detects facial expressions: smile, mouth open, eyebrow raise
        // Uses MediaPipe blendshapes for detection
        // =====================================================

        const ExpressionDetector = (function() {
            // Configuration with thresholds from PRD
            const config = {
                // Smile detection threshold (blendshape score > 0.4)
                smileThreshold: 0.4,
                // Mouth open detection threshold (blendshape score > 0.3)
                mouthOpenThreshold: 0.3,
                // Eyebrow raise detection threshold (blendshape score > 0.3)
                eyebrowRaiseThreshold: 0.3,
                // Hold duration required in milliseconds
                holdDuration: 500,
                // Smoothing factor for expression values (0-1, higher = more smoothing)
                smoothingFactor: 0.4,
                // Tolerance for position drift during hold (as fraction of threshold)
                holdTolerance: 0.8
            };

            // Blendshape category names used by MediaPipe
            const blendshapeNames = {
                // Smile detection - use mouth smile blendshapes
                smileLeft: 'mouthSmileLeft',
                smileRight: 'mouthSmileRight',
                // Mouth open detection - use jaw open blendshape
                jawOpen: 'jawOpen',
                // Additional mouth open indicators
                mouthOpen: 'mouthOpen',
                // Eyebrow raise detection
                browInnerUp: 'browInnerUp',
                browOuterUpLeft: 'browOuterUpLeft',
                browOuterUpRight: 'browOuterUpRight'
            };

            // State
            let state = {
                // Current smoothed expression values
                currentValues: {
                    smile: 0,
                    mouthOpen: 0,
                    eyebrowRaise: 0
                },
                // Raw values (before smoothing)
                rawValues: {
                    smile: 0,
                    mouthOpen: 0,
                    eyebrowRaise: 0
                },
                // Individual blendshape scores for debugging
                blendshapeScores: {
                    smileLeft: 0,
                    smileRight: 0,
                    jawOpen: 0,
                    browInnerUp: 0,
                    browOuterUpLeft: 0,
                    browOuterUpRight: 0
                },
                // Hold tracking for each expression type
                holdState: {
                    smile: { startTime: null, progress: 0, isHolding: false },
                    mouthOpen: { startTime: null, progress: 0, isHolding: false },
                    eyebrowRaise: { startTime: null, progress: 0, isHolding: false }
                },
                // Detection history
                detectionHistory: []
            };

            /**
             * Extract blendshape scores from face detection results
             * @param {Array} blendshapes - Array of blendshape categories from MediaPipe
             * @returns {Object} Object with blendshape scores
             */
            function extractBlendshapeScores(blendshapes) {
                const scores = {
                    smileLeft: 0,
                    smileRight: 0,
                    jawOpen: 0,
                    browInnerUp: 0,
                    browOuterUpLeft: 0,
                    browOuterUpRight: 0
                };

                if (!blendshapes || !Array.isArray(blendshapes)) {
                    return scores;
                }

                // Iterate through blendshapes and extract relevant scores
                for (const shape of blendshapes) {
                    switch (shape.categoryName) {
                        case blendshapeNames.smileLeft:
                            scores.smileLeft = shape.score;
                            break;
                        case blendshapeNames.smileRight:
                            scores.smileRight = shape.score;
                            break;
                        case blendshapeNames.jawOpen:
                            scores.jawOpen = shape.score;
                            break;
                        case blendshapeNames.browInnerUp:
                            scores.browInnerUp = shape.score;
                            break;
                        case blendshapeNames.browOuterUpLeft:
                            scores.browOuterUpLeft = shape.score;
                            break;
                        case blendshapeNames.browOuterUpRight:
                            scores.browOuterUpRight = shape.score;
                            break;
                    }
                }

                return scores;
            }

            /**
             * Calculate smile intensity from blendshape scores
             * Uses average of left and right mouth smile
             */
            function calculateSmileIntensity(scores) {
                return (scores.smileLeft + scores.smileRight) / 2;
            }

            /**
             * Calculate mouth open intensity from blendshape scores
             * Uses jaw open blendshape
             */
            function calculateMouthOpenIntensity(scores) {
                return scores.jawOpen;
            }

            /**
             * Calculate eyebrow raise intensity from blendshape scores
             * Uses combination of inner and outer brow raises
             */
            function calculateEyebrowRaiseIntensity(scores) {
                // Weight inner brow more as it's more distinctive
                const innerWeight = 0.5;
                const outerWeight = 0.25;

                return (scores.browInnerUp * innerWeight) +
                       (scores.browOuterUpLeft * outerWeight) +
                       (scores.browOuterUpRight * outerWeight);
            }

            /**
             * Apply exponential smoothing to reduce noise
             */
            function smoothValue(currentSmoothed, newRaw, factor) {
                return currentSmoothed * (1 - factor) + newRaw * factor;
            }

            /**
             * Check if an expression is currently active (above threshold)
             */
            function isExpressionActive(expressionType, value) {
                switch (expressionType) {
                    case 'smile':
                        return value >= config.smileThreshold;
                    case 'mouthOpen':
                        return value >= config.mouthOpenThreshold;
                    case 'eyebrowRaise':
                        return value >= config.eyebrowRaiseThreshold;
                    default:
                        return false;
                }
            }

            /**
             * Get the threshold for an expression type
             */
            function getThreshold(expressionType) {
                switch (expressionType) {
                    case 'smile':
                        return config.smileThreshold;
                    case 'mouthOpen':
                        return config.mouthOpenThreshold;
                    case 'eyebrowRaise':
                        return config.eyebrowRaiseThreshold;
                    default:
                        return 0.5;
                }
            }

            /**
             * Update hold state for a specific expression
             * @returns {Object} Updated hold state with detection result
             */
            function updateHoldState(expressionType, value, now) {
                const holdInfo = state.holdState[expressionType];
                const threshold = getThreshold(expressionType);
                const isActive = value >= threshold;
                const holdThreshold = threshold * config.holdTolerance;
                const isHoldingPosition = value >= holdThreshold;

                const result = {
                    isActive: isActive,
                    isHolding: false,
                    holdProgress: 0,
                    detected: false
                };

                if (isActive) {
                    if (holdInfo.isHolding && isHoldingPosition) {
                        // Continue holding
                        const holdTime = now - holdInfo.startTime;
                        holdInfo.progress = Math.min(holdTime / config.holdDuration, 1);
                        result.holdProgress = holdInfo.progress;
                        result.isHolding = true;

                        // Check if hold is complete
                        if (holdTime >= config.holdDuration) {
                            result.detected = true;
                            // Reset hold to allow detecting again
                            holdInfo.startTime = null;
                            holdInfo.progress = 0;
                            holdInfo.isHolding = false;
                        }
                    } else if (!holdInfo.isHolding) {
                        // Start new hold
                        holdInfo.startTime = now;
                        holdInfo.progress = 0;
                        holdInfo.isHolding = true;
                        result.isHolding = true;
                    } else if (!isHoldingPosition) {
                        // Position dropped below hold tolerance - restart
                        holdInfo.startTime = now;
                        holdInfo.progress = 0;
                    }
                } else {
                    // Expression not active - reset hold
                    holdInfo.startTime = null;
                    holdInfo.progress = 0;
                    holdInfo.isHolding = false;
                }

                return result;
            }

            /**
             * Process a frame and detect facial expressions
             * @param {Object} faceResults - Results from FaceLandmarker.detectForVideo()
             * @returns {Object} Detection result with expression status and metrics
             */
            function processFrame(faceResults) {
                const now = performance.now();

                // Default result
                const result = {
                    // Current expression values (0-1)
                    values: {
                        smile: 0,
                        mouthOpen: 0,
                        eyebrowRaise: 0
                    },
                    // Individual blendshape scores
                    blendshapeScores: state.blendshapeScores,
                    // Expression states (active/holding/detected)
                    expressions: {
                        smile: { isActive: false, isHolding: false, holdProgress: 0, detected: false },
                        mouthOpen: { isActive: false, isHolding: false, holdProgress: 0, detected: false },
                        eyebrowRaise: { isActive: false, isHolding: false, holdProgress: 0, detected: false }
                    },
                    // Overall detection flags
                    anyExpressionDetected: false,
                    detectedExpression: null
                };

                // Check if we have valid face data
                if (!faceResults || !faceResults.faceLandmarks || faceResults.faceLandmarks.length === 0) {
                    // Reset hold states when no face detected
                    Object.keys(state.holdState).forEach(key => {
                        state.holdState[key] = { startTime: null, progress: 0, isHolding: false };
                    });
                    return result;
                }

                // Get blendshapes from face results
                const blendshapes = faceResults.faceBlendshapes && faceResults.faceBlendshapes.length > 0
                    ? faceResults.faceBlendshapes[0].categories
                    : null;

                if (!blendshapes) {
                    return result;
                }

                // Extract blendshape scores
                state.blendshapeScores = extractBlendshapeScores(blendshapes);
                result.blendshapeScores = state.blendshapeScores;

                // Calculate raw expression intensities
                state.rawValues.smile = calculateSmileIntensity(state.blendshapeScores);
                state.rawValues.mouthOpen = calculateMouthOpenIntensity(state.blendshapeScores);
                state.rawValues.eyebrowRaise = calculateEyebrowRaiseIntensity(state.blendshapeScores);

                // Apply smoothing
                state.currentValues.smile = smoothValue(
                    state.currentValues.smile,
                    state.rawValues.smile,
                    config.smoothingFactor
                );
                state.currentValues.mouthOpen = smoothValue(
                    state.currentValues.mouthOpen,
                    state.rawValues.mouthOpen,
                    config.smoothingFactor
                );
                state.currentValues.eyebrowRaise = smoothValue(
                    state.currentValues.eyebrowRaise,
                    state.rawValues.eyebrowRaise,
                    config.smoothingFactor
                );

                // Update result values
                result.values = { ...state.currentValues };

                // Update hold states and check for detections
                const expressionTypes = ['smile', 'mouthOpen', 'eyebrowRaise'];

                for (const expressionType of expressionTypes) {
                    const value = state.currentValues[expressionType];
                    const holdResult = updateHoldState(expressionType, value, now);

                    result.expressions[expressionType] = holdResult;

                    // Track if any expression was detected
                    if (holdResult.detected) {
                        result.anyExpressionDetected = true;
                        result.detectedExpression = expressionType;

                        // Add to detection history
                        state.detectionHistory.push({
                            expression: expressionType,
                            value: value,
                            timestamp: now
                        });

                        console.log(`Expression detected: ${expressionType} (value: ${value.toFixed(2)}, held for ${config.holdDuration}ms)`);
                    }
                }

                return result;
            }

            /**
             * Reset the detector state
             * Call this when starting a new challenge
             */
            function reset() {
                state.currentValues = { smile: 0, mouthOpen: 0, eyebrowRaise: 0 };
                state.rawValues = { smile: 0, mouthOpen: 0, eyebrowRaise: 0 };
                state.holdState = {
                    smile: { startTime: null, progress: 0, isHolding: false },
                    mouthOpen: { startTime: null, progress: 0, isHolding: false },
                    eyebrowRaise: { startTime: null, progress: 0, isHolding: false }
                };
                state.detectionHistory = [];
                console.log('ExpressionDetector reset');
            }

            /**
             * Get current expression values
             */
            function getCurrentValues() {
                return { ...state.currentValues };
            }

            /**
             * Get current blendshape scores
             */
            function getBlendshapeScores() {
                return { ...state.blendshapeScores };
            }

            /**
             * Get hold progress for a specific expression
             */
            function getHoldProgress(expressionType) {
                if (state.holdState[expressionType]) {
                    return state.holdState[expressionType].progress;
                }
                return 0;
            }

            /**
             * Check if a specific expression is currently active
             */
            function isExpressionCurrentlyActive(expressionType) {
                const value = state.currentValues[expressionType];
                return isExpressionActive(expressionType, value);
            }

            /**
             * Check if currently holding a specific expression
             */
            function isHolding(expressionType) {
                if (state.holdState[expressionType]) {
                    return state.holdState[expressionType].isHolding;
                }
                return false;
            }

            /**
             * Get detection history
             */
            function getDetectionHistory() {
                return [...state.detectionHistory];
            }

            /**
             * Update configuration
             */
            function setConfig(newConfig) {
                Object.assign(config, newConfig);
            }

            /**
             * Get current configuration
             */
            function getConfig() {
                return { ...config };
            }

            // Public API
            return {
                processFrame,
                reset,
                getCurrentValues,
                getBlendshapeScores,
                getHoldProgress,
                isExpressionCurrentlyActive,
                isHolding,
                getDetectionHistory,
                setConfig,
                getConfig
            };
        })();

        // =====================================================
        // ANTI-SPOOFING MODULE
        // Detects photo/video spoofing attempts through multiple analysis methods
        // =====================================================

        const AntiSpoofingModule = (function() {
            // Configuration
            const config = {
                // Face position tracking
                positionHistorySize: 60, // ~2 seconds at 30fps
                maxPositionVariance: 0.15, // Max allowed variance in face position (too stable = photo)
                minPositionVariance: 0.001, // Min variance (some natural micro-movements expected)

                // 3D depth analysis
                depthHistorySize: 30,
                minDepthVariance: 0.0005, // Real faces have subtle depth changes

                // Blink pattern analysis
                blinkHistorySize: 10,
                minBlinkInterval: 1000, // Minimum 1 second between blinks
                maxBlinkInterval: 15000, // Maximum 15 seconds without blinking is suspicious
                naturalBlinkRate: { min: 10, max: 30 }, // Blinks per minute

                // Movement naturalness
                movementHistorySize: 30,
                minMovementVariance: 0.001, // Some movement expected

                // Scoring
                suspicionThreshold: 0.7, // Score above this triggers failure
                warningThreshold: 0.5
            };

            // Tracking state
            let state = {
                // Face position history (normalized x, y coordinates of face center)
                positionHistory: [],

                // Depth (z-coordinate) history for 3D analysis
                depthHistory: [],

                // Blink timestamps for pattern analysis
                blinkTimestamps: [],
                lastBlinkTime: null,

                // Movement magnitude history
                movementHistory: [],
                lastPosition: null,

                // Per-frame face landmark positions for micro-movement detection
                landmarkHistory: [],

                // Suspicion scores (0-1, higher = more suspicious)
                scores: {
                    positionStability: 0, // High if face too stable (photo)
                    depthVariance: 0, // High if no depth variance (flat image)
                    blinkPattern: 0, // High if blink pattern is unnatural
                    movementPattern: 0, // High if movements are too regular/mechanical
                    overallScore: 0
                },

                // Session tracking
                sessionStartTime: null,
                frameCount: 0,
                isActive: false,

                // Warnings issued
                warningsIssued: []
            };

            /**
             * Start anti-spoofing analysis for a new session
             */
            function startSession() {
                reset();
                state.sessionStartTime = performance.now();
                state.isActive = true;
                console.log('AntiSpoofingModule: Session started');
            }

            /**
             * Stop the current session
             */
            function stopSession() {
                state.isActive = false;
                console.log('AntiSpoofingModule: Session stopped');
            }

            /**
             * Reset all tracking data
             */
            function reset() {
                state.positionHistory = [];
                state.depthHistory = [];
                state.blinkTimestamps = [];
                state.lastBlinkTime = null;
                state.movementHistory = [];
                state.lastPosition = null;
                state.landmarkHistory = [];
                state.scores = {
                    positionStability: 0,
                    depthVariance: 0,
                    blinkPattern: 0,
                    movementPattern: 0,
                    overallScore: 0
                };
                state.sessionStartTime = null;
                state.frameCount = 0;
                state.isActive = false;
                state.warningsIssued = [];
            }

            /**
             * Calculate face center from landmarks
             */
            function calculateFaceCenter(landmarks) {
                // Use nose tip (landmark 1) and face boundary points for center calculation
                const noseTip = landmarks[1];
                const leftCheek = landmarks[234];
                const rightCheek = landmarks[454];
                const forehead = landmarks[10];
                const chin = landmarks[152];

                return {
                    x: (leftCheek.x + rightCheek.x + noseTip.x) / 3,
                    y: (forehead.y + chin.y + noseTip.y) / 3,
                    z: noseTip.z
                };
            }

            /**
             * Calculate variance of an array of numbers
             */
            function calculateVariance(values) {
                if (values.length < 2) return 0;
                const mean = values.reduce((sum, v) => sum + v, 0) / values.length;
                const squaredDiffs = values.map(v => Math.pow(v - mean, 2));
                return squaredDiffs.reduce((sum, v) => sum + v, 0) / values.length;
            }

            /**
             * Analyze face position stability
             * Photos tend to have extremely stable face positions
             */
            function analyzePositionStability() {
                if (state.positionHistory.length < config.positionHistorySize / 2) {
                    return 0; // Not enough data
                }

                const xValues = state.positionHistory.map(p => p.x);
                const yValues = state.positionHistory.map(p => p.y);

                const xVariance = calculateVariance(xValues);
                const yVariance = calculateVariance(yValues);
                const totalVariance = xVariance + yVariance;

                // Too little variance suggests a static image
                if (totalVariance < config.minPositionVariance) {
                    return Math.min(1, (config.minPositionVariance - totalVariance) / config.minPositionVariance + 0.5);
                }

                // Too much variance might indicate erratic movement (unusual)
                if (totalVariance > config.maxPositionVariance) {
                    return Math.min(0.3, (totalVariance - config.maxPositionVariance) / config.maxPositionVariance);
                }

                return 0;
            }

            /**
             * Analyze depth variance from z-coordinates
             * Flat images have very little z-variance over time
             */
            function analyzeDepthVariance() {
                if (state.depthHistory.length < config.depthHistorySize / 2) {
                    return 0;
                }

                const variance = calculateVariance(state.depthHistory);

                // Very low depth variance suggests a flat 2D surface
                if (variance < config.minDepthVariance) {
                    return Math.min(1, (config.minDepthVariance - variance) / config.minDepthVariance + 0.3);
                }

                return 0;
            }

            /**
             * Analyze blink patterns
             * Photos don't blink; videos have predictable blink patterns
             */
            function analyzeBlinkPattern() {
                const now = performance.now();
                const sessionDuration = now - state.sessionStartTime;

                // Need at least 5 seconds of data
                if (sessionDuration < 5000) {
                    return 0;
                }

                // Check if any blinks occurred
                if (state.blinkTimestamps.length === 0) {
                    // No blinks in 5+ seconds is suspicious
                    if (sessionDuration > 10000) {
                        return 0.8; // Very suspicious
                    }
                    return Math.min(0.5, sessionDuration / 20000);
                }

                // Check blink intervals for regularity (videos have predictable loops)
                if (state.blinkTimestamps.length >= 3) {
                    const intervals = [];
                    for (let i = 1; i < state.blinkTimestamps.length; i++) {
                        intervals.push(state.blinkTimestamps[i] - state.blinkTimestamps[i - 1]);
                    }

                    // Check for suspiciously regular intervals (looped video)
                    const intervalVariance = calculateVariance(intervals);
                    const meanInterval = intervals.reduce((a, b) => a + b, 0) / intervals.length;

                    // Very regular intervals suggest video loop
                    if (intervalVariance < 10000 && intervals.length >= 3) {
                        // Check if intervals are almost identical (within 100ms)
                        const maxDiff = Math.max(...intervals) - Math.min(...intervals);
                        if (maxDiff < 200) {
                            return 0.7; // Suspiciously regular
                        }
                    }

                    // Check blink rate
                    const blinksPerMinute = (state.blinkTimestamps.length / sessionDuration) * 60000;
                    if (blinksPerMinute < config.naturalBlinkRate.min / 2 ||
                        blinksPerMinute > config.naturalBlinkRate.max * 2) {
                        return 0.4; // Unusual blink rate
                    }
                }

                return 0;
            }

            /**
             * Analyze movement patterns for naturalness
             * Real faces have subtle micro-movements; replayed videos have mechanical patterns
             */
            function analyzeMovementPattern() {
                if (state.movementHistory.length < config.movementHistorySize / 2) {
                    return 0;
                }

                const variance = calculateVariance(state.movementHistory);

                // Too little movement suggests static image
                if (variance < config.minMovementVariance) {
                    return Math.min(0.6, (config.minMovementVariance - variance) / config.minMovementVariance + 0.2);
                }

                // Check for repetitive movement patterns (video loop detection)
                if (state.movementHistory.length >= 20) {
                    // Simple pattern detection: check if movement magnitudes repeat
                    const half = Math.floor(state.movementHistory.length / 2);
                    const firstHalf = state.movementHistory.slice(0, half);
                    const secondHalf = state.movementHistory.slice(half, half * 2);

                    let matchCount = 0;
                    for (let i = 0; i < half; i++) {
                        if (Math.abs(firstHalf[i] - secondHalf[i]) < 0.001) {
                            matchCount++;
                        }
                    }

                    // If patterns are very similar, might be looped video
                    if (matchCount / half > 0.8) {
                        return 0.6;
                    }
                }

                return 0;
            }

            /**
             * Process a frame of face detection results
             * Call this every frame during verification
             */
            function processFrame(faceResults, blinkResult) {
                if (!state.isActive) return;
                if (!faceResults || !faceResults.faceLandmarks || faceResults.faceLandmarks.length === 0) {
                    return;
                }

                state.frameCount++;
                const landmarks = faceResults.faceLandmarks[0];
                const now = performance.now();

                // Calculate face center
                const faceCenter = calculateFaceCenter(landmarks);

                // Track position history
                state.positionHistory.push({ x: faceCenter.x, y: faceCenter.y });
                if (state.positionHistory.length > config.positionHistorySize) {
                    state.positionHistory.shift();
                }

                // Track depth history
                state.depthHistory.push(faceCenter.z);
                if (state.depthHistory.length > config.depthHistorySize) {
                    state.depthHistory.shift();
                }

                // Track movement
                if (state.lastPosition) {
                    const dx = faceCenter.x - state.lastPosition.x;
                    const dy = faceCenter.y - state.lastPosition.y;
                    const movement = Math.sqrt(dx * dx + dy * dy);
                    state.movementHistory.push(movement);
                    if (state.movementHistory.length > config.movementHistorySize) {
                        state.movementHistory.shift();
                    }
                }
                state.lastPosition = { x: faceCenter.x, y: faceCenter.y };

                // Track blinks
                if (blinkResult && blinkResult.isCurrentlyBlinking && !state.lastBlinkTime) {
                    state.blinkTimestamps.push(now);
                    state.lastBlinkTime = now;
                    if (state.blinkTimestamps.length > config.blinkHistorySize) {
                        state.blinkTimestamps.shift();
                    }
                } else if (blinkResult && !blinkResult.isCurrentlyBlinking) {
                    state.lastBlinkTime = null;
                }

                // Update suspicion scores periodically (every 10 frames)
                if (state.frameCount % 10 === 0) {
                    updateSuspicionScores();
                }
            }

            /**
             * Update all suspicion scores
             */
            function updateSuspicionScores() {
                state.scores.positionStability = analyzePositionStability();
                state.scores.depthVariance = analyzeDepthVariance();
                state.scores.blinkPattern = analyzeBlinkPattern();
                state.scores.movementPattern = analyzeMovementPattern();

                // Calculate overall score (weighted average)
                state.scores.overallScore = (
                    state.scores.positionStability * 0.25 +
                    state.scores.depthVariance * 0.25 +
                    state.scores.blinkPattern * 0.25 +
                    state.scores.movementPattern * 0.25
                );
            }

            /**
             * Check if current session appears to be a spoofing attempt
             * Returns { isSuspicious, score, reasons[] }
             */
            function checkForSpoofing() {
                const reasons = [];

                if (state.scores.positionStability > config.warningThreshold) {
                    reasons.push('Face position unusually stable');
                }
                if (state.scores.depthVariance > config.warningThreshold) {
                    reasons.push('Insufficient depth variation detected');
                }
                if (state.scores.blinkPattern > config.warningThreshold) {
                    reasons.push('Unusual blink pattern detected');
                }
                if (state.scores.movementPattern > config.warningThreshold) {
                    reasons.push('Movement pattern appears unnatural');
                }

                return {
                    isSuspicious: state.scores.overallScore >= config.suspicionThreshold,
                    isWarning: state.scores.overallScore >= config.warningThreshold,
                    score: state.scores.overallScore,
                    reasons: reasons,
                    scores: { ...state.scores }
                };
            }

            /**
             * Get current anti-spoofing status
             */
            function getStatus() {
                return {
                    isActive: state.isActive,
                    frameCount: state.frameCount,
                    sessionDuration: state.sessionStartTime ? performance.now() - state.sessionStartTime : 0,
                    blinkCount: state.blinkTimestamps.length,
                    scores: { ...state.scores },
                    spoofingCheck: checkForSpoofing()
                };
            }

            /**
             * Update configuration
             */
            function setConfig(newConfig) {
                Object.assign(config, newConfig);
            }

            /**
             * Get configuration
             */
            function getConfig() {
                return { ...config };
            }

            return {
                startSession,
                stopSession,
                reset,
                processFrame,
                checkForSpoofing,
                getStatus,
                setConfig,
                getConfig
            };
        })();

        // =====================================================
        // CHALLENGE MANAGER MODULE
        // State machine for managing liveness verification challenges
        // States: INITIALIZING ‚Üí CALIBRATING ‚Üí PRESENTING ‚Üí DETECTING ‚Üí SUCCESS/FAILURE ‚Üí COMPLETED
        // =====================================================

        const ChallengeManager = (function() {
            // State constants
            const States = {
                INITIALIZING: 'INITIALIZING',
                CALIBRATING: 'CALIBRATING',
                PRESENTING: 'PRESENTING',
                DETECTING: 'DETECTING',
                SUCCESS: 'SUCCESS',
                FAILURE: 'FAILURE',
                COMPLETED: 'COMPLETED'
            };

            // Challenge type definitions
            const ChallengeTypes = {
                BLINK: {
                    id: 'blink',
                    name: 'Blink Your Eyes',
                    hint: 'Blink naturally 2-3 times',
                    icon: 'üëÅ',
                    detector: 'blink',
                    requiresHold: false,
                    targetCount: 2
                },
                TURN_LEFT: {
                    id: 'turn_left',
                    name: 'Turn Head Left',
                    hint: 'Turn your head to the left and hold',
                    icon: 'üëà',
                    detector: 'head',
                    requiresHold: true,
                    direction: 'left'
                },
                TURN_RIGHT: {
                    id: 'turn_right',
                    name: 'Turn Head Right',
                    hint: 'Turn your head to the right and hold',
                    icon: 'üëâ',
                    detector: 'head',
                    requiresHold: true,
                    direction: 'right'
                },
                LOOK_UP: {
                    id: 'look_up',
                    name: 'Look Up',
                    hint: 'Tilt your head up and hold',
                    icon: 'üëÜ',
                    detector: 'head',
                    requiresHold: true,
                    direction: 'up'
                },
                LOOK_DOWN: {
                    id: 'look_down',
                    name: 'Look Down',
                    hint: 'Tilt your head down and hold',
                    icon: 'üëá',
                    detector: 'head',
                    requiresHold: true,
                    direction: 'down'
                },
                SMILE: {
                    id: 'smile',
                    name: 'Smile',
                    hint: 'Give a big smile and hold',
                    icon: 'üòä',
                    detector: 'expression',
                    requiresHold: true,
                    expression: 'smile'
                },
                OPEN_MOUTH: {
                    id: 'open_mouth',
                    name: 'Open Your Mouth',
                    hint: 'Open your mouth wide and hold',
                    icon: 'üòÆ',
                    detector: 'expression',
                    requiresHold: true,
                    expression: 'mouthOpen'
                },
                RAISE_EYEBROWS: {
                    id: 'raise_eyebrows',
                    name: 'Raise Eyebrows',
                    hint: 'Raise your eyebrows and hold',
                    icon: 'üò≤',
                    detector: 'expression',
                    requiresHold: true,
                    expression: 'eyebrowRaise'
                }
            };

            // Configuration
            const config = {
                // Number of challenges per session
                totalChallenges: 4,
                // Time allowed per challenge in milliseconds
                challengeTimeout: 5000,
                // Time to display success message before moving to next challenge
                successDisplayDuration: 800,
                // Time to display failure message before retry
                failureDisplayDuration: 1000,
                // Calibration duration in milliseconds
                calibrationDuration: 2000,
                // Minimum time between state transitions (anti-spoofing)
                minTransitionDelay: 300,
                // Presentation delay before detection starts (base value)
                presentationDelay: 1000,
                // Anti-spoofing: Random delay range between challenges (ms)
                randomDelayMin: 200,
                randomDelayMax: 800,
                // Anti-spoofing: Enable continuous spoofing detection
                enableAntiSpoofing: true,
                // Anti-spoofing: Check for spoofing every N challenges
                spoofCheckInterval: 2
            };

            // State
            let state = {
                currentState: States.INITIALIZING,
                currentChallengeIndex: 0,
                challenges: [],
                completedChallenges: [],
                challengeStartTime: null,
                stateStartTime: null,
                lastStateChangeTime: 0,
                blinkCountAtStart: 0,
                isActive: false,
                failureReason: null
            };

            // Available challenge pool (excludes certain types for variety)
            const challengePool = [
                ChallengeTypes.BLINK,
                ChallengeTypes.TURN_LEFT,
                ChallengeTypes.TURN_RIGHT,
                ChallengeTypes.LOOK_UP,
                ChallengeTypes.LOOK_DOWN,
                ChallengeTypes.SMILE,
                ChallengeTypes.OPEN_MOUTH,
                ChallengeTypes.RAISE_EYEBROWS
            ];

            /**
             * Generate a random set of challenges with variety enforcement
             * Ensures no two consecutive challenges are too similar
             */
            function generateChallenges(count) {
                const selected = [];
                const availablePool = [...challengePool];

                for (let i = 0; i < count; i++) {
                    // Filter out similar challenges to the last selected one
                    let candidates = availablePool;

                    if (selected.length > 0) {
                        const lastChallenge = selected[selected.length - 1];
                        candidates = availablePool.filter(c => {
                            // Don't allow same detector type consecutively
                            if (c.detector === lastChallenge.detector) {
                                // Exception: allow different head directions
                                if (c.detector === 'head' && c.direction !== lastChallenge.direction) {
                                    return true;
                                }
                                // Exception: allow different expressions
                                if (c.detector === 'expression' && c.expression !== lastChallenge.expression) {
                                    return true;
                                }
                                return false;
                            }
                            return true;
                        });

                        // If no candidates left, use full pool
                        if (candidates.length === 0) {
                            candidates = availablePool;
                        }
                    }

                    // Random selection from candidates
                    const randomIndex = Math.floor(Math.random() * candidates.length);
                    const challenge = candidates[randomIndex];
                    selected.push(challenge);

                    // Remove selected challenge from pool to avoid duplicates
                    const poolIndex = availablePool.findIndex(c => c.id === challenge.id);
                    if (poolIndex > -1) {
                        availablePool.splice(poolIndex, 1);
                    }

                    // Refill pool if needed
                    if (availablePool.length === 0) {
                        availablePool.push(...challengePool.filter(c =>
                            !selected.slice(-3).some(s => s.id === c.id)
                        ));
                    }
                }

                return selected;
            }

            /**
             * Transition to a new state
             */
            function transitionTo(newState) {
                const now = performance.now();

                // Enforce minimum transition delay for anti-spoofing
                if (now - state.lastStateChangeTime < config.minTransitionDelay) {
                    return false;
                }

                const previousState = state.currentState;
                state.currentState = newState;
                state.stateStartTime = now;
                state.lastStateChangeTime = now;

                console.log(`ChallengeManager: ${previousState} ‚Üí ${newState}`);

                // Handle state entry actions
                onStateEnter(newState);

                return true;
            }

            /**
             * Handle state entry actions
             */
            function onStateEnter(newState) {
                switch (newState) {
                    case States.INITIALIZING:
                        updateUI('Initializing...', '', '');
                        break;

                    case States.CALIBRATING:
                        updateUI('Hold still...', 'Calibrating', 'Keep your face centered in the oval');
                        HeadMovementDetector.resetCalibration();
                        break;

                    case States.PRESENTING:
                        presentCurrentChallenge();
                        break;

                    case States.DETECTING:
                        state.challengeStartTime = performance.now();
                        startChallengeTimer();
                        // Record blink count for blink challenges
                        state.blinkCountAtStart = BlinkDetector.getBlinkCount();
                        break;

                    case States.SUCCESS:
                        handleChallengeSuccess();
                        break;

                    case States.FAILURE:
                        handleChallengeFailure();
                        break;

                    case States.COMPLETED:
                        handleVerificationComplete();
                        break;
                }
            }

            /**
             * Generate a random delay for anti-spoofing unpredictability
             */
            function getRandomDelay() {
                return config.randomDelayMin + Math.random() * (config.randomDelayMax - config.randomDelayMin);
            }

            function presentCurrentChallenge() {
                const challenge = state.challenges[state.currentChallengeIndex];
                if (!challenge) return;

                // Update UI with challenge info
                elements.challengeNumber.textContent = state.currentChallengeIndex + 1;
                elements.challengeIcon.textContent = challenge.icon;
                elements.challengeName.textContent = challenge.name;
                elements.challengeHint.textContent = challenge.hint;
                elements.challengeTimer.textContent = `${(config.challengeTimeout / 1000).toFixed(0)}s remaining`;
                elements.progressFill.style.width = '0%';
                elements.holdPercent.textContent = '0%';

                // Update progress indicators
                updateProgressIndicators();

                // Show challenge panel
                elements.challengePanel.classList.remove('hidden');

                // Reset detectors for the new challenge
                if (challenge.detector === 'blink') {
                    BlinkDetector.reset();
                } else if (challenge.detector === 'head') {
                    HeadMovementDetector.reset();
                } else if (challenge.detector === 'expression') {
                    ExpressionDetector.reset();
                }

                // Anti-spoofing: Add random delay to base presentation delay
                // This makes timing unpredictable and harder to spoof with pre-recorded videos
                const randomDelay = getRandomDelay();
                const totalDelay = config.presentationDelay + randomDelay;

                // Transition to detecting after presentation delay (with randomized component)
                setTimeout(() => {
                    if (state.currentState === States.PRESENTING) {
                        transitionTo(States.DETECTING);
                    }
                }, totalDelay);
            }

            /**
             * Start the challenge timer countdown
             */
            let timerInterval = null;
            function startChallengeTimer() {
                // Clear any existing timer
                if (timerInterval) {
                    clearInterval(timerInterval);
                }

                timerInterval = setInterval(() => {
                    if (state.currentState !== States.DETECTING) {
                        clearInterval(timerInterval);
                        return;
                    }

                    const elapsed = performance.now() - state.challengeStartTime;
                    const remaining = Math.max(0, config.challengeTimeout - elapsed);
                    const seconds = Math.ceil(remaining / 1000);

                    elements.challengeTimer.textContent = `${seconds}s remaining`;

                    // Check for timeout
                    if (remaining <= 0) {
                        clearInterval(timerInterval);
                        state.failureReason = 'timeout';
                        transitionTo(States.FAILURE);
                    }
                }, 100);
            }

            /**
             * Update progress indicators to show completed challenges
             */
            function updateProgressIndicators() {
                elements.indicators.forEach((indicator, index) => {
                    indicator.classList.remove('active', 'completed');

                    if (index < state.currentChallengeIndex) {
                        indicator.classList.add('completed');
                    } else if (index === state.currentChallengeIndex) {
                        indicator.classList.add('active');
                    }
                });
            }

            /**
             * Handle successful challenge completion
             */
            function handleChallengeSuccess() {
                clearInterval(timerInterval);

                const challenge = state.challenges[state.currentChallengeIndex];
                state.completedChallenges.push(challenge);

                // Update UI to show success with animations
                elements.faceGuide.classList.add('detected', 'success-glow');
                elements.faceGuide.classList.remove('warning');
                elements.progressFill.style.width = '100%';
                elements.progressFill.classList.add('completing');
                elements.holdPercent.textContent = '100%';
                updateStatus('Challenge completed!');

                // Mark indicator as completed with animation
                const currentIndicator = elements.indicators[state.currentChallengeIndex];
                currentIndicator.classList.add('completing');
                currentIndicator.classList.remove('active');

                // After animation, set completed state
                setTimeout(() => {
                    currentIndicator.classList.remove('completing');
                    currentIndicator.classList.add('completed');
                }, 400);

                // Move to next challenge or complete
                setTimeout(() => {
                    // Clean up animation classes
                    elements.faceGuide.classList.remove('success-glow');
                    elements.progressFill.classList.remove('completing');

                    state.currentChallengeIndex++;

                    if (state.currentChallengeIndex >= state.challenges.length) {
                        // Final anti-spoofing check before completing verification
                        if (config.enableAntiSpoofing) {
                            const finalCheck = AntiSpoofingModule.checkForSpoofing();
                            if (finalCheck.isSuspicious) {
                                console.log('AntiSpoofing: Final check detected suspicious activity', finalCheck);
                                state.failureReason = 'spoof_detected';
                                transitionTo(States.FAILURE);
                                return;
                            }
                        }
                        transitionTo(States.COMPLETED);
                    } else {
                        // Add slide animation for challenge panel
                        elements.challengePanel.classList.add('slide-out');
                        setTimeout(() => {
                            transitionTo(States.PRESENTING);
                            elements.challengePanel.classList.remove('slide-out');
                            elements.challengePanel.classList.add('slide-in');
                            setTimeout(() => {
                                elements.challengePanel.classList.remove('slide-in');
                            }, 300);
                        }, 300);
                    }
                }, config.successDisplayDuration);
            }

            /**
             * Handle challenge failure
             */
            function handleChallengeFailure() {
                clearInterval(timerInterval);

                // Stop anti-spoofing session on failure
                if (config.enableAntiSpoofing) {
                    AntiSpoofingModule.stopSession();
                }

                const reason = state.failureReason || 'unknown';
                let message = 'Challenge failed';

                switch (reason) {
                    case 'timeout':
                        message = 'Time expired - Try again';
                        break;
                    case 'face_lost':
                        message = 'Face lost - Keep your face visible';
                        break;
                    case 'spoof_detected':
                        message = 'Verification failed - Please use a live camera';
                        break;
                    default:
                        message = 'Challenge failed - Try again';
                }

                updateStatus(message);
                elements.faceGuide.classList.add('warning');
                elements.faceGuide.classList.remove('detected');

                // Show failure on result screen
                elements.resultScreen.classList.add('visible');
                elements.resultScreen.classList.add('failure');
                elements.resultIcon.textContent = '‚úó';
                elements.resultTitle.textContent = 'Verification Failed';
                elements.resultMessage.textContent = message;

                // Hide challenge panel
                elements.challengePanel.classList.add('hidden');
                elements.controlBtn.classList.add('hidden');

                state.isActive = false;
            }

            /**
             * Handle verification completion (all challenges passed)
             */
            function handleVerificationComplete() {
                clearInterval(timerInterval);

                // Stop anti-spoofing session on completion
                if (config.enableAntiSpoofing) {
                    AntiSpoofingModule.stopSession();
                    // Log final anti-spoofing status
                    const status = AntiSpoofingModule.getStatus();
                    console.log('AntiSpoofing: Final session status', status);
                }

                // Animate challenge panel out before showing result
                elements.challengePanel.classList.add('slide-out');

                setTimeout(() => {
                    // Hide challenge panel and control button
                    elements.challengePanel.classList.add('hidden');
                    elements.challengePanel.classList.remove('slide-out');
                    elements.controlBtn.classList.add('hidden');

                    // Update UI to show success with animation
                    elements.resultScreen.classList.remove('failure');
                    elements.resultScreen.classList.add('visible');
                    elements.resultIcon.textContent = '‚úì';
                    elements.resultTitle.textContent = 'Verification Complete';
                    elements.resultMessage.textContent = 'You have been verified as a real person.';

                    // Add success glow to face guide
                    elements.faceGuide.classList.add('detected', 'success-glow');
                    elements.faceGuide.classList.remove('warning');

                    updateStatus('Verification successful!');
                    console.log('Verification completed successfully!');
                }, 300);

                state.isActive = false;
            }

            /**
             * Update UI helper function
             */
            function updateUI(status, challengeName, challengeHint) {
                if (status) updateStatus(status);
                if (challengeName) elements.challengeName.textContent = challengeName;
                if (challengeHint) elements.challengeHint.textContent = challengeHint;
            }

            /**
             * Process detection results from the main detection loop
             * Call this every frame while verification is active
             */
            function processFrame(faceResults, blinkResult, headResult, expressionResult) {
                if (!state.isActive) return;

                const now = performance.now();

                // Check for face presence
                const hasFace = faceResults && faceResults.faceLandmarks && faceResults.faceLandmarks.length > 0;

                // Process anti-spoofing analysis
                if (config.enableAntiSpoofing && hasFace) {
                    AntiSpoofingModule.processFrame(faceResults, blinkResult);

                    // Check for spoofing at configured intervals
                    if (state.currentChallengeIndex > 0 &&
                        state.currentChallengeIndex % config.spoofCheckInterval === 0 &&
                        state.currentState === States.DETECTING) {
                        const spoofCheck = AntiSpoofingModule.checkForSpoofing();
                        if (spoofCheck.isSuspicious) {
                            console.log('AntiSpoofing: Suspicious activity detected', spoofCheck);
                            state.failureReason = 'spoof_detected';
                            transitionTo(States.FAILURE);
                            return;
                        }
                    }
                }

                switch (state.currentState) {
                    case States.CALIBRATING:
                        if (!hasFace) {
                            updateStatus('Position your face in the oval');
                            return;
                        }

                        // Wait for head movement calibration
                        if (HeadMovementDetector.isCalibrated()) {
                            const elapsed = now - state.stateStartTime;
                            if (elapsed >= config.calibrationDuration) {
                                transitionTo(States.PRESENTING);
                            } else {
                                const progress = Math.floor((elapsed / config.calibrationDuration) * 100);
                                updateStatus(`Calibrating... ${progress}%`);
                            }
                        }
                        break;

                    case States.DETECTING:
                        if (!hasFace) {
                            state.failureReason = 'face_lost';
                            // Give a brief grace period before failing
                            setTimeout(() => {
                                if (state.currentState === States.DETECTING && !currentFaceResults) {
                                    transitionTo(States.FAILURE);
                                }
                            }, 500);
                            return;
                        }

                        // Process current challenge detection
                        const challenge = state.challenges[state.currentChallengeIndex];
                        if (!challenge) return;

                        let challengeCompleted = false;
                        let holdProgress = 0;

                        switch (challenge.detector) {
                            case 'blink':
                                // Check if user has blinked enough times
                                const newBlinks = blinkResult.blinkCount - state.blinkCountAtStart;
                                if (newBlinks >= challenge.targetCount) {
                                    challengeCompleted = true;
                                }
                                // Show blink progress
                                holdProgress = Math.min(newBlinks / challenge.targetCount, 1);
                                updateStatus(`Blinks: ${newBlinks}/${challenge.targetCount}`);
                                break;

                            case 'head':
                                // Check if head is turned in correct direction and held
                                if (headResult.detectedDirection === challenge.direction) {
                                    challengeCompleted = true;
                                } else if (headResult.direction === challenge.direction) {
                                    holdProgress = headResult.holdProgress;
                                    const percent = Math.floor(holdProgress * 100);
                                    updateStatus(`Hold... ${percent}%`);
                                } else {
                                    const yaw = headResult.yawFromBaseline?.toFixed(1) || '0';
                                    const pitch = headResult.pitchFromBaseline?.toFixed(1) || '0';
                                    updateStatus(`Yaw: ${yaw}¬∞ | Pitch: ${pitch}¬∞`);
                                }
                                break;

                            case 'expression':
                                // Check if expression is detected and held
                                const expr = expressionResult.expressions[challenge.expression];
                                if (expr && expr.detected) {
                                    challengeCompleted = true;
                                } else if (expr && expr.isHolding) {
                                    holdProgress = expr.holdProgress;
                                    const percent = Math.floor(holdProgress * 100);
                                    updateStatus(`Hold... ${percent}%`);
                                } else {
                                    const value = expressionResult.values[challenge.expression];
                                    const percent = Math.floor(value * 100);
                                    updateStatus(`${challenge.name}: ${percent}%`);
                                }
                                break;
                        }

                        // Update progress bar
                        elements.progressFill.style.width = `${holdProgress * 100}%`;
                        elements.holdPercent.textContent = `${Math.floor(holdProgress * 100)}%`;

                        // Check if challenge completed
                        if (challengeCompleted) {
                            transitionTo(States.SUCCESS);
                        }
                        break;
                }
            }

            /**
             * Start the verification process
             */
            function start() {
                console.log('ChallengeManager: Starting verification');

                // Generate random challenges
                state.challenges = generateChallenges(config.totalChallenges);
                state.currentChallengeIndex = 0;
                state.completedChallenges = [];
                state.isActive = true;
                state.failureReason = null;

                console.log('Generated challenges:', state.challenges.map(c => c.name));

                // Reset all detectors
                BlinkDetector.reset();
                HeadMovementDetector.resetCalibration();
                ExpressionDetector.reset();

                // Start anti-spoofing session
                if (config.enableAntiSpoofing) {
                    AntiSpoofingModule.startSession();
                }

                // Hide result screen, show challenge panel
                elements.resultScreen.classList.remove('visible');
                elements.resultScreen.classList.remove('failure');
                elements.challengePanel.classList.remove('hidden');
                elements.controlBtn.classList.add('hidden');

                // Start with calibration
                transitionTo(States.CALIBRATING);
            }

            /**
             * Stop/reset the verification process
             */
            function stop() {
                state.isActive = false;
                state.currentState = States.INITIALIZING;
                clearInterval(timerInterval);

                // Stop anti-spoofing session
                if (config.enableAntiSpoofing) {
                    AntiSpoofingModule.stopSession();
                }

                console.log('ChallengeManager: Stopped');
            }

            /**
             * Retry the current challenge without restarting everything
             */
            function retryCurrentChallenge() {
                // Clear any existing timer
                clearInterval(timerInterval);

                state.failureReason = null;
                state.isActive = true;

                // Hide result screen, show challenge panel
                elements.resultScreen.classList.remove('visible');
                elements.resultScreen.classList.remove('failure');
                elements.challengePanel.classList.remove('hidden');

                // Reset faceGuide state
                elements.faceGuide.classList.remove('warning');
                elements.faceGuide.classList.add('detected');

                // Restart anti-spoofing session
                if (config.enableAntiSpoofing) {
                    AntiSpoofingModule.startSession();
                }

                // Transition to PRESENTING for the current challenge
                transitionTo(States.PRESENTING);

                console.log('ChallengeManager: Retrying current challenge');
            }

            /**
             * Reset for retry
             */
            function reset() {
                stop();
                state.challenges = [];
                state.completedChallenges = [];
                state.currentChallengeIndex = 0;
                state.failureReason = null;

                // Reset anti-spoofing module
                if (config.enableAntiSpoofing) {
                    AntiSpoofingModule.reset();
                }

                // Reset UI
                elements.resultScreen.classList.remove('visible');
                elements.resultScreen.classList.remove('failure');
                elements.challengePanel.classList.remove('hidden');
                elements.challengePanel.classList.remove('slide-out', 'slide-in');
                elements.controlBtn.classList.remove('hidden');
                elements.controlBtn.disabled = false;

                // Clean up animation classes
                elements.faceGuide.classList.remove('success-glow');
                elements.progressFill.classList.remove('completing');
                elements.indicators.forEach(indicator => {
                    indicator.classList.remove('completing', 'completed', 'active');
                });

                updateProgressIndicators();
                console.log('ChallengeManager: Reset');
            }

            /**
             * Check if verification is currently active
             */
            function isActive() {
                return state.isActive;
            }

            /**
             * Get current state
             */
            function getCurrentState() {
                return state.currentState;
            }

            /**
             * Get current challenge
             */
            function getCurrentChallenge() {
                return state.challenges[state.currentChallengeIndex] || null;
            }

            /**
             * Get progress info
             */
            function getProgress() {
                return {
                    current: state.currentChallengeIndex + 1,
                    total: state.challenges.length,
                    completed: state.completedChallenges.length,
                    challenges: state.challenges.map(c => c.name)
                };
            }

            /**
             * Update configuration
             */
            function setConfig(newConfig) {
                Object.assign(config, newConfig);
            }

            /**
             * Get configuration
             */
            function getConfig() {
                return { ...config };
            }

            // Expose States for external use
            return {
                States,
                ChallengeTypes,
                start,
                stop,
                reset,
                retryCurrentChallenge,
                processFrame,
                isActive,
                getCurrentState,
                getCurrentChallenge,
                getProgress,
                setConfig,
                getConfig
            };
        })();

        // Track face detection state for warnings
        let noFaceDetectedStartTime = null;
        const NO_FACE_WARNING_DELAY = 3000; // Show warning after 3 seconds of no face

        /**
         * Initialize the application with timeout and error handling
         */
        async function initializeApp() {
            console.log('Liveness Detection App - Initializing...');

            // Disable button until both camera and model are ready
            elements.controlBtn.disabled = true;

            // Check browser compatibility first
            if (!checkBrowserCompatibility()) {
                return;
            }

            // Set up initialization timeout (30 seconds)
            const INIT_TIMEOUT = 30000;
            let initTimedOut = false;

            const timeoutPromise = new Promise((_, reject) => {
                setTimeout(() => {
                    initTimedOut = true;
                    reject(new Error('Initialization timeout'));
                }, INIT_TIMEOUT);
            });

            try {
                // Initialize camera and model in parallel with timeout
                const initPromise = Promise.all([
                    initializeCamera(),
                    initializeFaceLandmarker()
                ]);

                const [cameraResult, modelResult] = await Promise.race([
                    initPromise,
                    timeoutPromise
                ]);

                // Check if both initialized successfully
                if (cameraResult && modelResult) {
                    hideError();
                    checkAndEnableStartButton();
                    // Start detection loop immediately for face positioning feedback
                    startDetectionLoop();
                } else {
                    if (!cameraResult) {
                        console.error('Camera initialization failed');
                    }
                    if (!modelResult) {
                        console.error('Model initialization failed');
                    }
                }
            } catch (error) {
                if (initTimedOut) {
                    showError(
                        'The app is taking too long to initialize. Please check your internet connection and try again.',
                        'INITIALIZATION_TIMEOUT'
                    );
                }
                console.error('Initialization error:', error);
            }
        }

        /**
         * Retry initialization after an error
         */
        async function retryInitialization() {
            console.log('Retrying initialization...');
            hideError();
            updateStatus('Retrying...');

            // Stop any existing streams
            stopCamera();

            // Reset state
            isModelReady = false;
            isModelLoading = false;
            isCameraReady = false;
            faceLandmarker = null;

            // Reinitialize
            await initializeApp();
        }

        // Initialize the app on page load
        document.addEventListener('DOMContentLoaded', async () => {
            // Initialize app
            await initializeApp();

            // Error retry button click handler
            elements.errorRetryBtn.addEventListener('click', async () => {
                await retryInitialization();
            });

            // Error help button click handler
            elements.errorHelpBtn.addEventListener('click', () => {
                const helpText = elements.errorHelpBtn.dataset.helpText || 'Please check your camera settings and refresh the page.';
                alert(helpText);
            });

            // Control button click handler
            elements.controlBtn.addEventListener('click', () => {
                if (!isAppReady()) {
                    console.error('App not ready');
                    showWarningToast('Please wait for initialization to complete');
                    return;
                }

                // Check if face is detected before starting
                if (!currentFaceResults || !currentFaceResults.faceLandmarks || currentFaceResults.faceLandmarks.length === 0) {
                    showWarningToast('Please position your face in the oval first');
                    return;
                }

                // Start detection if not running
                if (!isDetectionRunning) {
                    startDetectionLoop();
                }

                // Start the verification challenge sequence
                ChallengeManager.start();
            });

            // Retry button click handler
            elements.retryBtn.addEventListener('click', () => {
                // Retry current challenge without restarting everything
                ChallengeManager.retryCurrentChallenge();

                // Hide face warning if visible
                hideFaceWarning();

                // Ensure detection loop is running
                if (!isDetectionRunning) {
                    startDetectionLoop();
                }

                updateStatus('Position your face in the oval and click Start');
            });
        });
    </script>
</body>
</html>
